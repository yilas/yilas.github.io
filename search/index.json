[{"content":"Introduction The AWS Certified Cloud Practitioner (CLF-C02) exam is intended for individuals who can effectively demonstrate overall knowledge of the AWS Cloud, independent of a specific job role. The exam validates a candidate’s ability to complete the following tasks:\n Explain the value of the AWS Cloud. Understand and explain the AWS shared responsibility model. Understand security best practices. Understand AWS Cloud costs, economics, and billing practices. Describe and position the core AWS services, including compute, network, database, and storage services. Identify AWS services for common use cases.  Technology Section Introduction  Lien : ici  EC2 Connectivity Pricing Features Lambda Additional compute services AWS Fargate  manage containers scale serverless  AWS Fargate est un service de calcul sans serveur (serverless) fourni par Amazon Web Services (AWS) pour le déploiement et la gestion de conteneurs. Les conteneurs sont des unités d\u0026rsquo;application légères et portables qui peuvent être exécutées de manière cohérente sur n\u0026rsquo;importe quel environnement compatible avec les conteneurs.\nPoints clés   Sans gestion des serveurs : Avec AWS Fargate, vous n\u0026rsquo;avez pas à vous soucier de la gestion des serveurs sous-jacents. Vous pouvez simplement déployer vos conteneurs sans avoir à provisionner ni à gérer l\u0026rsquo;infrastructure sous-jacente.\n  Gestion des ressources : AWS Fargate gère automatiquement les ressources nécessaires pour exécuter vos conteneurs, telles que le calcul, la mémoire et le stockage. Vous spécifiez simplement les ressources nécessaires pour chaque conteneur, et Fargate s\u0026rsquo;occupe du reste.\n  Isolation des tâches : Chaque tâche (ensemble de conteneurs) s\u0026rsquo;exécute dans son propre environnement isolé, assurant ainsi la sécurité et l\u0026rsquo;isolation des ressources entre les différentes charges de travail.\n  Facturation basée sur l\u0026rsquo;utilisation : Vous payez uniquement pour les ressources de calcul que vous consommez réellement. Cela offre une flexibilité accrue, car vous n\u0026rsquo;avez pas besoin de provisionner des ressources fixes à l\u0026rsquo;avance.\n  Intégration avec les services AWS : Fargate s\u0026rsquo;intègre facilement avec d\u0026rsquo;autres services AWS tels que Amazon Elastic Container Registry (ECR), Amazon ECS (Elastic Container Service), AWS CloudWatch pour la surveillance, et d\u0026rsquo;autres services qui facilitent le déploiement, la gestion et la mise à l\u0026rsquo;échelle des conteneurs.\n  Support de Docker : AWS Fargate prend en charge les conteneurs Docker, ce qui signifie que vous pouvez utiliser des images Docker pour empaqueter vos applications et leurs dépendances, puis les déployer sur Fargate.\n  En résumé, AWS Fargate simplifie le déploiement et la gestion de conteneurs en éliminant la nécessité de gérer l\u0026rsquo;infrastructure sous-jacente, tout en offrant une expérience sans serveur pour l\u0026rsquo;exécution de vos charges de travail conteneurisées. Cela permet aux développeurs de se concentrer davantage sur le développement d\u0026rsquo;applications et de services, plutôt que sur la gestion des serveurs et de l\u0026rsquo;infrastructure.\nAWS Lightsail  deploy preconfigured application : wordpress, etc Simple screens Include VM, SSD based storage, DNS, static IP  AWS Lightsail est un service cloud d\u0026rsquo;Amazon Web Services (AWS) qui simplifie le processus de déploiement, de gestion et de mise à l\u0026rsquo;échelle d\u0026rsquo;applications web et de sites web. Conçu pour être facile à utiliser, AWS Lightsail est particulièrement adapté aux utilisateurs qui ne sont pas des experts en administration système ou en gestion d\u0026rsquo;infrastructure.\nCaractéristiques clés   Facilité d\u0026rsquo;utilisation : AWS Lightsail offre une interface utilisateur conviviale qui simplifie la configuration et la gestion des ressources. Il est conçu pour être accessible aux utilisateurs qui ne sont pas nécessairement des experts en cloud computing.\n  Sélection de plans préconfigurés : AWS Lightsail propose des plans préconfigurés qui incluent des combinaisons de ressources telles que la puissance de calcul, la mémoire, le stockage et le transfert de données. Les utilisateurs peuvent choisir un plan qui correspond à leurs besoins sans avoir à se préoccuper de la configuration détaillée.\n  Applications préinstallées : AWS Lightsail permet aux utilisateurs de déployer des applications préconfigurées, telles que WordPress, Drupal, Joomla, ou des applications de développement comme Node.js et LAMP (Linux, Apache, MySQL, PHP). Cela accélère le processus de mise en place d\u0026rsquo;une application.\n  Stockage géré : AWS Lightsail inclut un stockage SSD géré, ce qui simplifie la gestion du stockage pour les utilisateurs. Ils peuvent facilement attacher, détacher et sauvegarder des disques sans se soucier des détails de l\u0026rsquo;infrastructure sous-jacente.\n  Mise à l\u0026rsquo;échelle simple : Bien que AWS Lightsail offre une approche simple pour démarrer, les utilisateurs peuvent toujours évoluer vers d\u0026rsquo;autres services AWS plus avancés (comme Amazon EC2) pour bénéficier de fonctionnalités plus avancées et de ressources supplémentaires.\n  Facturation prévisible : AWS Lightsail propose une tarification simple et transparente basée sur des forfaits mensuels. Cela permet aux utilisateurs de planifier leurs coûts plus facilement sans surprises liées à la consommation de ressources.\n  En résumé, AWS Lightsail est une solution cloud adaptée aux utilisateurs qui recherchent une approche simple et préconfigurée pour le déploiement d\u0026rsquo;applications web, sans avoir à gérer de manière approfondie l\u0026rsquo;infrastructure sous-jacente. C\u0026rsquo;est une option idéale pour les petites entreprises, les développeurs individuels ou toute personne ayant des besoins simples en matière d\u0026rsquo;hébergement web.\nAWS Outposts With AWS Outposts, AWS delivers and installs servers in your internal data center, which allows you to support data sovereignty requirements.\n Run cloud services in your internal datacenter support wordloads that need to remain on-prem dut to latency or data sovereignty need AWS delivers and intalls severs in your internal DC Used for a hybrid experience Have access to the cloud services and APIs to develop apps on-prem  AWS Outposts est un service proposé par Amazon Web Services (AWS) qui permet d\u0026rsquo;étendre l\u0026rsquo;infrastructure AWS dans le centre de données physique du client. Il s\u0026rsquo;agit d\u0026rsquo;une solution hybride qui combine les avantages du cloud avec la possibilité de conserver certaines charges de travail sur site, offrant ainsi une approche plus flexible pour les entreprises ayant des exigences spécifiques en matière de localisation des données, de latence, de conformité ou de réglementation.\nCaractéristiques clés   Extension du Cloud AWS : AWS Outposts étend l\u0026rsquo;infrastructure et les services AWS sur site, permettant aux entreprises de bénéficier de la même expérience de cloud computing qu\u0026rsquo;AWS tout en maintenant des charges de travail sur site lorsque nécessaire.\n  Configurations variées : AWS Outposts propose différentes configurations, y compris des racks 1U et 2U, pour répondre à divers besoins en matière de calcul, de stockage et de gestion des données.\n  Services AWS sur site : Les services AWS tels que Amazon EC2, Amazon EBS, Amazon RDS et d\u0026rsquo;autres peuvent être déployés sur site via AWS Outposts. Cela permet aux entreprises d\u0026rsquo;exécuter des applications localement tout en utilisant les services cloud gérés par AWS.\n  Intégration transparente : AWS Outposts est conçu pour s\u0026rsquo;intégrer de manière transparente avec les services AWS dans le cloud. Cela permet aux entreprises de gérer l\u0026rsquo;ensemble de leur infrastructure à partir de la console AWS, unifiant ainsi la gestion des ressources sur site et dans le cloud.\n  Mises à jour et maintenance automatisées : AWS Outposts gère automatiquement les mises à jour logicielles et la maintenance, garantissant que les systèmes restent à jour avec les dernières fonctionnalités et correctifs de sécurité.\n  Options de connectivité : AWS Outposts offre des options de connectivité flexibles, permettant aux entreprises de choisir entre une connectivité locale directe ou une connexion via un réseau AWS Direct Connect.\n  Sécurité et conformité : Les charges de travail exécutées sur AWS Outposts bénéficient des mêmes fonctionnalités de sécurité et de conformité que celles disponibles dans le cloud AWS, assurant une protection adéquate des données et des applications.\n  En résumé, AWS Outposts offre une solution hybride qui permet aux entreprises de bénéficier des avantages du cloud tout en répondant à des exigences spécifiques nécessitant l\u0026rsquo;exécution de certaines charges de travail sur site. Cela offre une flexibilité accrue pour les entreprises ayant des besoins variés en matière de déploiement et de gestion de l\u0026rsquo;infrastructure.\nAWS Batch  Allow to process large workloads in smaller chunks (or batches) Runs hundreds and thousands of smaller batch processing jobs Dynamically provisions instances based on volume  Time to remember when Studying for the Exam S3 S3 is an object storage service for the cloud that is highly available :\n Objects : for files are stored in Buckets or directories  Security :\n ACL policies access point policies  Feat :\n Enable versionning S3 access log S3 is regional service but bucket names must be globally unique  Data accessibility Durability Important so your objects are never lost or compromised.\nAvailability You can access your data when you need it.\nStorage Classes Additional storage services Amazon Elastic Block Store (AWS EBS)  attach volume to ec2 data persists when instance is not running can only be attached to one instance in the same AZ Tied to one AZ (replicate if needed to be used in another AZ) Lon term data storage Quickly accessible  AWS EBS est un service de stockage de blocs hautement évolutif et fiable proposé par Amazon Web Services (AWS). Il offre un stockage persistant pour les instances Amazon EC2 (Elastic Compute Cloud). Les volumes EBS sont conçus pour être utilisés comme des disques durs traditionnels, fournissant une capacité de stockage fiable et performante pour les applications et les données des instances EC2.\nCaractéristiques clés   Persistant et Haute Performance : Les volumes EBS fournissent un stockage persistant qui persiste indépendamment de l\u0026rsquo;état de l\u0026rsquo;instance EC2. Ils offrent également des performances élevées pour les applications qui nécessitent un accès rapide aux données.\n  Différents Types de Volumes : AWS EBS propose plusieurs types de volumes pour répondre à divers besoins en matière de performances et de coûts, y compris les volumes magnétiques standard, les volumes de disques SSD (Solid State Drive) de type gp2 (General Purpose SSD), io1 (Provisioned IOPS SSD), st1 (Throughput Optimized HDD) et sc1 (Cold HDD).\n  Instantanés (Snapshots) : Les utilisateurs peuvent créer des instantanés EBS, qui sont des copies point-in-time des volumes EBS. Ces instantanés peuvent être utilisés pour sauvegarder les données, cloner des volumes, ou créer de nouveaux volumes à partir d\u0026rsquo;instantanés existants.\n  Élasticité et Redimensionnement : Les volumes EBS peuvent être redimensionnés en cours d\u0026rsquo;exécution, permettant aux utilisateurs d\u0026rsquo;ajuster la capacité de stockage de leurs instances EC2 sans interruption de service.\n  Haute Disponibilité : Les données stockées sur les volumes EBS sont automatiquement répliquées dans la même zone de disponibilité AWS, garantissant une haute disponibilité et une tolérance aux pannes.\n  Intégration avec Amazon EC2 : Les volumes EBS sont facilement attachés et détachés des instances EC2. Ils peuvent être utilisés comme stockage principal pour le système d\u0026rsquo;exploitation, les applications ou les bases de données.\n  Sécurité : EBS offre des fonctionnalités de sécurité telles que le cryptage des données au repos, assurant la confidentialité des données stockées.\n  En résumé, Amazon Elastic Block Store (AWS EBS) est un service de stockage de blocs flexible, scalable et hautement performant, conçu pour répondre aux besoins de stockage persistant des instances Amazon EC2 dans le cloud AWS.\nEC2 Storage  Can be EBS, EFS or Instance Store (ephemeral). Physically attached to the host computterd. Cannot be removed. Faster with higher I/O Storage is temporary data Temporaray storage Data replicated accross instances  Links :\n https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html  Amazon Elastic File System (AWS EFS)  EFS is a serverless networkd file system for sharing files Only supports linux FS ACcessible accross different AZ in the same region More expensive than EBS Recommended  for main directorues for business-critical apps lift-and-shift existing enterprise apps    Amazon Elastic File System (EFS) est un service de stockage de fichiers entièrement géré proposé par Amazon Web Services (AWS). Conçu pour être hautement évolutif et compatible avec les charges de travail nécessitant un stockage partagé, AWS EFS permet aux instances EC2 d\u0026rsquo;accéder à un système de fichiers partagé de manière simultanée.\nCaractéristiques clés   Stockage Partagé : EFS offre un système de fichiers partagé entre plusieurs instances EC2, permettant aux applications d\u0026rsquo;accéder aux données de manière concurrente. Cela est particulièrement utile pour les charges de travail nécessitant une cohérence des données entre différentes instances.\n  Évolutivité Automatique : EFS peut évoluer automatiquement pour s\u0026rsquo;adapter à la croissance de la quantité de données et du nombre d\u0026rsquo;instances EC2 accédant au système de fichiers. Il élimine la nécessité de provisionner à l\u0026rsquo;avance la capacité de stockage.\n  Performance Élevée : EFS offre une performance élevée, adaptée à une large gamme d\u0026rsquo;applications, y compris les applications nécessitant un accès fréquent et rapide aux fichiers.\n  Prise en Charge de Protocoles Standard : EFS prend en charge les protocoles standard de l\u0026rsquo;industrie tels que NFS (Network File System), ce qui le rend compatible avec de nombreuses applications et systèmes d\u0026rsquo;exploitation.\n  Sécurité et Gestion des Accès : EFS propose des fonctionnalités de sécurité, y compris le cryptage des données en transit et au repos. De plus, il permet de gérer les accès avec des autorisations basées sur les groupes de sécurité EC2.\n  Intégration avec d\u0026rsquo;Autres Services AWS : EFS s\u0026rsquo;intègre facilement avec d\u0026rsquo;autres services AWS tels que Amazon EC2, AWS Lambda, Amazon ECS, et d\u0026rsquo;autres, facilitant l\u0026rsquo;intégration dans des architectures cloud complexes.\n  Accès Mondial : EFS prend en charge l\u0026rsquo;accès mondial, permettant aux instances EC2 de différentes régions AWS d\u0026rsquo;accéder au même système de fichiers.\n  Utilisations Courantes   Applications Web à Échelle Élevée : EFS est adapté aux applications web qui nécessitent un stockage partagé à grande échelle, par exemple, les sites web dynamiques avec plusieurs instances EC2.\n  Analyse de Données : Pour les charges de travail d\u0026rsquo;analyse de données nécessitant un accès simultané à de grands ensembles de données.\n  Déploiements de Conteneurs : EFS peut être utilisé pour le stockage partagé dans des déploiements de conteneurs avec des services tels qu\u0026rsquo;Amazon ECS.\n  En résumé, [Amazon Elastic File System (EFS)](https://aws.amazon.com/efs/?nc1=h_ls offre une solution de stockage de fichiers entièrement gérée, hautement évolutive, et adaptée aux charges de travail nécessitant un stockage partagé entre plusieurs instances EC2.\nAWS Storage Gateway  Hybrid storage service Connect on-prem and cloud data Suppports a hybrid model Recommended for :  moving backups to the cloud reducing costs for hybrid cloud storage low latency access to data    AWS Storage Gateway est un service d\u0026rsquo;Amazon Web Services (AWS) qui facilite l\u0026rsquo;intégration de solutions de stockage sur site avec le cloud AWS. Il permet d\u0026rsquo;établir une connexion transparente entre les systèmes de stockage sur site et les services de stockage dans le cloud, facilitant ainsi la migration, l\u0026rsquo;archivage et la sauvegarde des données.\nCaractéristiques clés   Intégration Hybride : Storage Gateway offre une solution hybride en permettant aux applications sur site d\u0026rsquo;accéder aux données stockées dans le cloud et vice versa. Il agit comme une passerelle entre le stockage sur site et le stockage dans le cloud.\n  Différents Protocoles de Stockage : Storage Gateway prend en charge différents protocoles de stockage, notamment iSCSI pour les blocs, NFS pour les fichiers, et SMB pour les fichiers en mode Windows. Cela assure une compatibilité avec une variété d\u0026rsquo;applications et d\u0026rsquo;environnements.\n  Sauvegarde et Archivage : Il permet la sauvegarde et l\u0026rsquo;archivage des données sur le cloud AWS, offrant une solution rentable pour la protection des données et la rétention à long terme.\n  Accélération des Transferts : Storage Gateway utilise des fonctionnalités telles que la mise en cache locale pour améliorer les performances des applications en accélérant les transferts de données entre le site et le cloud.\n  Sécurité et Cryptage : Les données transitant entre la passerelle et le cloud sont sécurisées à l\u0026rsquo;aide de protocoles de chiffrement. De plus, Storage Gateway prend en charge le chiffrement des données au repos sur le cloud.\n  Intégration avec d\u0026rsquo;Autres Services AWS : Il s\u0026rsquo;intègre facilement avec d\u0026rsquo;autres services AWS tels que Amazon S3, Amazon Glacier, et Amazon EBS, offrant ainsi une flexibilité accrue dans le choix des solutions de stockage dans le cloud.\n  Facilité de Déploiement et de Gestion : Storage Gateway est facile à déployer et à gérer, offrant une interface utilisateur web pour la configuration et la surveillance de la passerelle.\n  Modes de Déploiement   Gateway de Fichier (File Gateway) : Utilisé pour l\u0026rsquo;accès aux objets stockés dans Amazon S3 en tant que fichiers standards, avec des protocoles NFS ou SMB.\n  Gateway de Volume (Volume Gateway) : Permet d\u0026rsquo;utiliser le stockage cloud comme des volumes iSCSI locaux, avec des modes de stockage en ligne ou en cache.\n  Gateway de Bande (Tape Gateway) : Offre une interface iSCSI pour les applications de sauvegarde afin d\u0026rsquo;archiver des données sur Amazon S3 ou Glacier sous forme de bandes virtuelles.\n  En résumé, [AWS Storage Gateway](https://aws.amazon.com/storagegateway/?nc1=h_ls offre une solution flexible et transparente pour l\u0026rsquo;intégration des systèmes de stockage sur site avec le cloud AWS, facilitant la gestion, la sauvegarde, et l\u0026rsquo;archivage des données de manière efficace et sécurisée.\nAWS Backup  help manage data backups from EC2, EBS, EFS, etc. create a backup plan that includes frequency and retention  Links :\n https://aws.amazon.com/backup/?nc1=h_ls  AWS Backup est un service de sauvegarde entièrement géré proposé par Amazon Web Services (AWS). Il offre une solution centralisée pour la gestion des sauvegardes de données à travers différents services AWS, simplifiant ainsi la gestion et la protection des données.\nCaractéristiques clés   Centralisation des Sauvegardes : AWS Backup permet la centralisation des sauvegardes pour plusieurs services AWS tels que Amazon EBS, Amazon RDS, Amazon DynamoDB, Amazon EFS, et d\u0026rsquo;autres. Cela offre une vue unifiée des sauvegardes à travers diverses ressources AWS.\n  Planification des Sauvegardes : Les utilisateurs peuvent définir des plans de sauvegarde pour automatiser le processus de sauvegarde. Ceci inclut la définition de la fréquence des sauvegardes, la rétention des sauvegardes, et d\u0026rsquo;autres paramètres personnalisables.\n  Sauvegardes Point-in-Time : AWS Backup prend en charge les sauvegardes point-in-time, permettant de restaurer les données à un état spécifique, ce qui est crucial pour la récupération après des incidents.\n  Gestion des Rétentions : Les utilisateurs peuvent définir des politiques de rétention pour déterminer combien de temps les sauvegardes doivent être conservées. Cela aide à respecter les exigences de conformité et à optimiser l\u0026rsquo;utilisation de l\u0026rsquo;espace de stockage.\n  Intégration avec AWS Organizations : AWS Backup s\u0026rsquo;intègre avec AWS Organizations, permettant une gestion centralisée des sauvegardes pour plusieurs comptes AWS au sein d\u0026rsquo;une organisation.\n  Restauration Sélective : Les utilisateurs peuvent restaurer sélectivement des éléments spécifiques à partir d\u0026rsquo;une sauvegarde, offrant une flexibilité dans le processus de récupération.\n  Compatibilité avec AWS Storage Gateway : AWS Backup est compatible avec les passerelles de stockage AWS Storage Gateway, ce qui permet de gérer les sauvegardes pour les données stockées sur site.\n  Utilisations Courantes   Protection des Données Critiques : AWS Backup est utilisé pour protéger les données critiques des applications en automatisant le processus de sauvegarde et de récupération.\n  Conformité et Gouvernance : Il est utilisé pour répondre aux exigences de conformité en matière de conservation des données et pour mettre en œuvre des politiques de gouvernance des données.\n  Gestion Centralisée : AWS Backup est adopté par les organisations avec plusieurs comptes AWS pour une gestion centralisée des sauvegardes à travers différents services.\n  En résumé, [AWS Backup](https://aws.amazon.com/backup/?nc1=h_ls simplifie et centralise la gestion des sauvegardes pour les services AWS, offrant ainsi une solution complète pour la protection et la récupération des données dans le cloud AWS.\nTime to remember when Studying for the Exam Understanding Content Delivery Services Amazon CloudFront  CDN : Cloud Delivery Network  Low latency mechanism to deliver content quickly and efficiently based on geographic location   CloudFront is a CDN  make available content globally restricts it based on location Speeds up delivery of static and dynamic web content USes edge locatios to cache content    Links :\n https://my.visme.co/view/w48r7ygo-s03-l09-understanding-content-delivery-services https://aws.amazon.com/fr/cloudfront/  Amazon CloudFront est un service de réseau de diffusion de contenu (CDN) proposé par Amazon Web Services (AWS). Il offre une distribution de contenu hautement sécurisée, évolutive et basée sur des emplacements périphériques dans le monde entier, permettant d\u0026rsquo;améliorer la performance et la disponibilité des sites web et des applications.\nCaractéristiques clés   Livraison Rapide de Contenu : CloudFront accélère la livraison de contenu statique et dynamique, y compris des images, des vidéos, des scripts, et d\u0026rsquo;autres ressources, en acheminant les données par le chemin le plus rapide disponible.\n  Répartition Mondiale : Avec une présence mondiale de points de présence (PoPs), CloudFront permet une distribution efficace du contenu à partir de serveurs situés à proximité des utilisateurs finaux, réduisant ainsi la latence et améliorant les performances.\n  Intégration avec d\u0026rsquo;Autres Services AWS : CloudFront s\u0026rsquo;intègre facilement avec d\u0026rsquo;autres services AWS tels que Amazon S3, Elastic Load Balancing, AWS Shield pour la protection contre les attaques DDoS, et AWS WAF pour la protection contre les menaces web.\n  Sécurité et Chiffrement : CloudFront prend en charge le chiffrement SSL/TLS pour assurer la sécurité des données pendant le transfert. Il offre également la possibilité d\u0026rsquo;utiliser des certificats gérés par AWS Certificate Manager (ACM) pour simplifier la gestion des certificats.\n  Contrôle d\u0026rsquo;Accès : CloudFront offre des fonctionnalités de contrôle d\u0026rsquo;accès, y compris l\u0026rsquo;authentification d\u0026rsquo;utilisateur, les politiques de referrer, et la possibilité de restreindre l\u0026rsquo;accès à du contenu privé.\n  Tarification Flexible : La tarification de CloudFront est basée sur l\u0026rsquo;utilisation réelle, offrant une flexibilité aux utilisateurs pour payer uniquement les ressources qu\u0026rsquo;ils consomment.\n  Streaming de Médias : CloudFront prend en charge le streaming de médias en continu avec des fonctionnalités telles que Amazon CloudFront Live Smooth Streaming pour les vidéos en direct et Amazon CloudFront On-Demand Smooth Streaming pour les vidéos à la demande.\n  Utilisations Courantes   Distribution de Contenu Web : CloudFront est utilisé pour accélérer la livraison de contenu web statique et dynamique, améliorant ainsi l\u0026rsquo;expérience utilisateur.\n  Streaming Vidéo : Il est utilisé pour le streaming de vidéos en direct et à la demande, offrant une diffusion fluide et une faible latence.\n  Applications Web à l\u0026rsquo;Échelle Mondiale : CloudFront est adopté par les applications web nécessitant une distribution mondiale pour garantir une performance optimale pour les utilisateurs dans le monde entier.\n  Sécurisation du Contenu : Il est utilisé pour sécuriser le contenu en fournissant des fonctionnalités de chiffrement et de contrôle d\u0026rsquo;accès.\n  En résumé, Amazon CloudFront est un service CDN puissant qui offre une distribution de contenu rapide, sécurisée et évolutive, répondant aux besoins de performances des applications web modernes à l\u0026rsquo;échelle mondiale.\nAmazon Global Accelerator  Amazon Global Accelerator sends your users through the AWS global network when accessing your content, speeding up delivery  Improve latency and availability of single-region applications Sends traffic through the AWS global network infrastructure 60% performance boost Automatically re-routes traffic to healthy available regional endpoints    Amazon Global Accelerator est un service proposé par Amazon Web Services (AWS) qui permet d\u0026rsquo;améliorer la disponibilité et la performance des applications en routant le trafic des utilisateurs vers les ressources AWS à travers le réseau mondial d\u0026rsquo;Amazon.\nCaractéristiques clés   Routage Basé sur la Performance : Global Accelerator utilise des adresses IP statiques pour acheminer le trafic vers des points de terminaison (endpoints) AWS, en choisissant automatiquement le chemin le plus optimal basé sur la latence et la santé des ressources.\n  Anycast IP : Les adresses IP Anycast d\u0026rsquo;Amazon Global Accelerator restent constantes dans le temps, offrant une stabilité pour les applications et permettant aux utilisateurs d\u0026rsquo;accéder aux ressources via des adresses IP fixes, indépendamment de leur emplacement géographique.\n  Évolutivité Automatique : Global Accelerator peut évoluer automatiquement pour faire face à des changements dans le trafic et dans la topologie des ressources, assurant ainsi une performance constante même en cas de variations importantes.\n  Intégration avec AWS Services : Il s\u0026rsquo;intègre facilement avec d\u0026rsquo;autres services AWS tels que Elastic Load Balancing (ELB), AWS Global Accelerator, et AWS Shield pour une protection contre les attaques DDoS.\n  Sécurité Intégrée : Global Accelerator offre des fonctionnalités de sécurité telles que le chiffrement SSL/TLS pour sécuriser le trafic entre les utilisateurs finaux et les ressources AWS.\n  Monitoring et Analytics : Les utilisateurs peuvent surveiller les performances de leurs applications grâce aux métriques Amazon CloudWatch et aux journaux AWS CloudTrail fournis par Global Accelerator.\n  Gestion des Points de Terminaison : Il permet de gérer facilement les points de terminaison, en ajoutant, supprimant ou en modifiant leur configuration de manière transparente.\n  Utilisations Courantes   Amélioration de la Performance : Global Accelerator est utilisé pour optimiser la performance des applications en acheminant le trafic par le chemin le plus optimal, réduisant ainsi la latence et améliorant l\u0026rsquo;expérience utilisateur.\n  Disponibilité Élevée : Il contribue à améliorer la disponibilité des applications en dirigeant le trafic vers des points de terminaison sains et en évoluant automatiquement pour faire face à des variations de trafic.\n  Protection contre les Attaques DDoS : Global Accelerator offre une intégration avec AWS Shield pour la protection contre les attaques par déni de service distribué (DDoS).\n  Applications à l\u0026rsquo;Échelle Mondiale : Il est particulièrement adapté aux applications qui nécessitent une distribution mondiale avec une disponibilité et une performance élevées.\n  En résumé, Amazon Global Accelerator est un service conçu pour optimiser la performance des applications à l\u0026rsquo;échelle mondiale, offrant une solution de routage basée sur la performance, une évolutivité automatique, et une intégration transparente avec d\u0026rsquo;autres services AWS.\nAmazon S3 Transfer Acceleration Amazon S3 Transfer Acceleration improves content uploads and downloads to and from S3 buckets\n Fast transfer of files over long distances Uses CloudFront’s globally distributed edge locations Customers around the world can upload to a central bucket  Amazon S3 Transfer Acceleration est une fonctionnalité d\u0026rsquo;Amazon Simple Storage Service (S3) qui permet d\u0026rsquo;accélérer le transfert de données vers et depuis les compartiments S3 en utilisant le réseau mondial d\u0026rsquo;Amazon CloudFront.\nCaractéristiques clés   Transfert Rapide : Transfer Acceleration accélère le transfert de fichiers vers et depuis S3 en optimisant le chemin du réseau pour réduire la latence et améliorer la vitesse de transfert.\n  Intégration avec CloudFront : Il utilise les points de présence (PoPs) du réseau mondial de CloudFront pour acheminer le trafic de transfert de données, permettant ainsi une diffusion rapide et efficace du contenu.\n  Adresses URL Spécifiques : Pour utiliser Transfer Acceleration, des adresses URL spécifiques au domaine sont fournies, permettant aux utilisateurs de tirer parti de cette fonctionnalité sans nécessiter de modification significative de leurs applications.\n  Sécurité Intégrée : Transfer Acceleration prend en charge le chiffrement SSL/TLS pour garantir la sécurité des données pendant le transfert. Il permet également d\u0026rsquo;utiliser des clés de chiffrement gérées par AWS Key Management Service (KMS).\n  Tarification Séparée : Bien que le transfert via Transfer Acceleration soit facturé séparément, il offre une option économique pour les transferts de données rapides en comparaison avec les coûts standard de transfert de données S3.\n  Utilisations Courantes   Transfert de Gros Volumes de Données : Transfer Acceleration est particulièrement utile pour le transfert rapide de gros volumes de données vers et depuis S3, réduisant ainsi le temps nécessaire pour déplacer des fichiers importants.\n  Distribution de Contenu Rapide : Il peut être utilisé pour accélérer la distribution de contenu à partir de compartiments S3, améliorant ainsi la performance des applications qui dépendent de la récupération rapide de fichiers.\n  Collaboration à Distance : Transfer Acceleration facilite la collaboration à distance en permettant des transferts de fichiers rapides et fiables, même entre des emplacements géographiques éloignés.\n  Sauvegarde et Récupération Rapides : Les utilisateurs peuvent tirer parti de Transfer Acceleration pour effectuer des sauvegardes et des récupérations rapides de données critiques stockées dans S3.\n  En résumé, Amazon S3 Transfer Acceleration est une fonctionnalité qui améliore la vitesse de transfert des données vers et depuis Amazon S3 en utilisant le réseau mondial de CloudFront, offrant ainsi une solution efficace pour les transferts rapides de gros volumes de données.\nTime to remember when Studying for the Exam Understanding Networking Services: VPC and Subcomponents  Lien : https://my.visme.co/view/y4mnz11g-s03-l10-understanding-networking-services-vpc-and-subcomponents  Amazon Virtual Private Cloud (VPC) Amazon Virtual Private Cloud (VPC) is a foundational service that allows you to create a secure private network in the AWS cloud where you launch your resources.\n Private virtual network : ip address range, subnet, security groups, route tables Launch resources like EC2 inside VPC Isolate and protect resources VPC spans AZ in a Region  Description:\n Single Region AZ : one or more separated DC (power redundant, etc.) VPC spans the 2 AZ AZ : private subnet and public subnet NACL : Network Access Control List Router =\u0026gt; route table Internet GW : access to internet from VPC  VPC peering allows you to connect 2 VPCs together\nAmazon Virtual Private Cloud (VPC) est un service d\u0026rsquo;Amazon Web Services (AWS) qui permet aux utilisateurs de créer un réseau virtuel isolé dans le cloud. Cela offre un contrôle total sur l\u0026rsquo;environnement réseau, y compris la sélection des adresses IP, la configuration des tables de routage, et la création de sous-réseaux.\nCaractéristiques clés   Isolation Virtuelle : VPC permet de créer des réseaux virtuels isolés logiquement dans le cloud, permettant aux utilisateurs de définir leurs propres plages d\u0026rsquo;adresses IP, tables de routage et sous-réseaux.\n  Personnalisation des Adresses IP : Les utilisateurs peuvent personnaliser leurs plages d\u0026rsquo;adresses IP en créant des sous-réseaux publics et privés, fournissant ainsi une flexibilité dans la conception de l\u0026rsquo;architecture réseau.\n  Connectivité au Réseau d\u0026rsquo;Entreprise : VPC offre des options de connectivité pour intégrer le réseau AWS avec le réseau d\u0026rsquo;entreprise, y compris l\u0026rsquo;utilisation de connexions VPN (Virtual Private Network) ou AWS Direct Connect.\n  Sécurité et Contrôle d\u0026rsquo;Accès : Les groupes de sécurité et les listes de contrôle d\u0026rsquo;accès réseau (ACL) permettent de définir des règles de sécurité pour contrôler le trafic entrant et sortant des instances déployées dans le VPC.\n  Options de Sous-réseaux : Les utilisateurs peuvent créer des sous-réseaux publics et privés, où les sous-réseaux publics ont un accès direct à Internet, tandis que les sous-réseaux privés sont accessibles uniquement via un équilibreur de charge ou une instance NAT (Network Address Translation).\n  Évolutivité Automatique : VPC offre la possibilité de dimensionner automatiquement les ressources en fonction de la demande, permettant ainsi d\u0026rsquo;ajuster dynamiquement la taille du réseau en fonction des besoins.\n  Connectivité Entre VPC : Plusieurs VPC peuvent être connectés les uns aux autres à l\u0026rsquo;intérieur de la même région AWS, facilitant ainsi la création d\u0026rsquo;architectures réseau complexes.\n  Intégration avec d\u0026rsquo;Autres Services AWS : VPC s\u0026rsquo;intègre avec d\u0026rsquo;autres services AWS tels que Amazon S3, Amazon RDS, Amazon EC2, et d\u0026rsquo;autres, permettant aux utilisateurs de créer des solutions cloud complètes.\n  Utilisations Courantes   Hébergement d\u0026rsquo;Applications Multi-Tier : VPC est utilisé pour héberger des applications multi-tier en créant des sous-réseaux pour chaque couche d\u0026rsquo;application, offrant ainsi une isolation et un contrôle d\u0026rsquo;accès.\n  Connectivité au Réseau d\u0026rsquo;Entreprise : Les organisations utilisent VPC pour connecter leur infrastructure sur site au cloud AWS de manière sécurisée via VPN ou AWS Direct Connect.\n  Déploiement d\u0026rsquo;Applications d\u0026rsquo;Entreprise : VPC est utilisé pour déployer des applications d\u0026rsquo;entreprise dans le cloud AWS avec un contrôle total sur l\u0026rsquo;infrastructure réseau.\n  Hébergement de Sites Web : VPC est utilisé pour héberger des sites web en configurant des sous-réseaux publics avec un accès direct à Internet.\n  En résumé, Amazon VPC offre un environnement réseau virtuel sécurisé et personnalisable dans le cloud AWS, permettant aux utilisateurs de créer des architectures réseau flexibles et évolutives selon leurs besoins.\nUnderstanding Networking Services: Additional Networking Services  Liens :  https://my.visme.co/view/n03yg113-s03-l11-understanding-networking-services-additional-networking-services    Amazon Route 53 Amazon Route 53 est un service de gestion de domaines et de système de noms de domaine (DNS) proposé par Amazon Web Services (AWS). Il offre des fonctionnalités avancées de résolution DNS, de gestion de domaine et de routage du trafic internet pour les applications hébergées dans le cloud AWS.\nCaractéristiques clés   Enregistrements DNS : Route 53 permet de gérer une variété d\u0026rsquo;enregistrements DNS tels que A (adresse IPv4), AAAA (adresse IPv6), CNAME (alias de nom de domaine), MX (mail exchange), et bien d\u0026rsquo;autres.\n  Gestion de Domaine : Les utilisateurs peuvent enregistrer de nouveaux domaines via Route 53 ou transférer des domaines existants vers le service. Il offre une console web conviviale pour la gestion complète des domaines.\n  Résolution DNS Rapide : Route 53 offre une résolution DNS rapide et fiable, avec un réseau mondial de serveurs de noms distribués dans plusieurs régions AWS.\n  Sécurité DNS : Il propose DNSSEC (Domain Name System Security Extensions) pour renforcer la sécurité des enregistrements DNS, aidant à prévenir les attaques telles que le détournement DNS.\n  Routing de Trafic : Route 53 permet le routage du trafic basé sur des politiques, notamment la répartition de charge pondérée, la latence, la géolocalisation, et la disponibilité des points de terminaison.\n  Health Checks : Les utilisateurs peuvent configurer des contrôles de santé pour les points de terminaison, permettant à Route 53 de rediriger le trafic loin des points de terminaison non sains.\n  Intégration avec d\u0026rsquo;Autres Services AWS : Il s\u0026rsquo;intègre étroitement avec d\u0026rsquo;autres services AWS tels que Amazon S3, Elastic Load Balancing, Amazon CloudFront, et AWS Elastic Beanstalk.\n  Utilisation pour des Domaines Privés : Route 53 prend en charge la résolution DNS pour les domaines privés à l\u0026rsquo;intérieur de VPC (Virtual Private Cloud).\n  Utilisations Courantes   Gestion de Domaines : Route 53 est utilisé pour enregistrer, transférer et gérer des domaines de manière centralisée.\n  Routage de Trafic : Il est utilisé pour configurer des politiques de routage avancées basées sur des critères tels que la latence, la géolocalisation et la disponibilité des points de terminaison.\n  Résolution DNS Rapide : Les entreprises utilisent Route 53 pour bénéficier d\u0026rsquo;une résolution DNS rapide et fiable pour leurs applications hébergées dans le cloud AWS.\n  Health Checks : Il est utilisé pour surveiller la santé des points de terminaison et rediriger le trafic en fonction de leur disponibilité.\n  En résumé, Amazon Route 53 offre une solution complète pour la gestion de domaines, la résolution DNS rapide et le routage avancé du trafic, facilitant ainsi la mise en œuvre de services web et d\u0026rsquo;applications cloud hautement disponibles.\nAWS Direct Connect AWS Direct Connect is a dedicated physical network connection from your on-premises data center to AWS :\n Dedicated physical network connection Connects your on-premises data center to AWS Data travels over a private network Supports a hybrid environment  When to use :\n Transfer large datasets to AWS transfer internal data directly to AWS, bypassing yhe internet service provider Build hybrid environments  AWS Direct Connect est un service d\u0026rsquo;Amazon Web Services (AWS) qui offre une connexion réseau dédiée et privée entre l\u0026rsquo;infrastructure d\u0026rsquo;une entreprise et les services cloud d\u0026rsquo;AWS. Cette connexion directe élimine la nécessité de passer par l\u0026rsquo;internet public, offrant ainsi une bande passante plus élevée, une faible latence et une sécurité renforcée pour les transferts de données entre les locaux de l\u0026rsquo;entreprise et le cloud AWS.\nCaractéristiques clés   Connexion Dédiée : AWS Direct Connect permet d\u0026rsquo;établir des connexions réseau dédiées entre le réseau de l\u0026rsquo;entreprise et AWS, ce qui élimine la dépendance vis-à-vis de l\u0026rsquo;internet public.\n  Bande Passante Évolutive : Les utilisateurs peuvent choisir parmi divers niveaux de bande passante, allant de 50 Mbps à 100 Gbps, en fonction de leurs besoins en matière de transfert de données.\n  Faible Latence : Grâce à la connexion directe à AWS, Direct Connect offre une faible latence, répondant aux exigences des applications nécessitant une réponse rapide.\n  Connexion Privée au Cloud : AWS Direct Connect établit une connexion privée aux services AWS tels que Amazon S3, Amazon EC2, Amazon VPC, améliorant ainsi la sécurité des données transitant entre le réseau local et le cloud.\n  Intégration avec d\u0026rsquo;Autres Services AWS : Il s\u0026rsquo;intègre de manière transparente avec d\u0026rsquo;autres services AWS tels que Amazon Virtual Private Cloud (VPC), Elastic Load Balancing, AWS Transit Gateway, etc.\n  Redondance et Fiabilité : AWS Direct Connect offre des options de redondance, permettant d\u0026rsquo;établir des connexions redondantes pour garantir une disponibilité et une fiabilité élevées.\n  Connectivité avec Plusieurs Emplacements : Les utilisateurs peuvent établir des connexions directes à partir de plusieurs emplacements géographiques, fournissant une connectivité globale.\n  Utilisations Courantes   Transfert de Données Volumineuses : AWS Direct Connect est utilisé pour transférer efficacement et en toute sécurité des volumes importants de données entre les infrastructures locales et le cloud AWS.\n  Mise en Place d\u0026rsquo;Environnements Hybrides : Il est couramment utilisé pour créer des environnements informatiques hybrides, permettant aux entreprises de profiter des avantages du cloud tout en maintenant certaines ressources sur site.\n  Applications Sensibles à la Latence : Les entreprises utilisent Direct Connect pour prendre en charge des applications sensibles à la latence, telles que les applications financières ou les applications de jeu en ligne.\n  Migration de Données : Il est un choix populaire lors de migrations massives de données vers le cloud AWS, offrant une bande passante élevée et des délais réduits.\n  AWS Direct Connect offre ainsi une solution fiable et performante pour établir des connexions réseau dédiées entre les environnements sur site et le cloud AWS, répondant aux exigences de performances, de sécurité et de fiabilité.\nAWS VPN Lien : https://aws.amazon.com/vpn/\nSite-to-Site VPN creates a secure connection between your internal networks and your AWS VPCs :\n Similar to Direct Connect, but data travels over the public internet Data is automatically encrypted Connects your on-premises data center to AWS Supports a hybrid environment  AWS VPN (Amazon Virtual Private Network) est un service d\u0026rsquo;Amazon Web Services qui permet aux entreprises d\u0026rsquo;établir des connexions réseau sécurisées entre leur infrastructure sur site et les services cloud AWS. AWS VPN offre une solution de réseau privé virtuel pour une connectivité sécurisée et chiffrée, permettant aux utilisateurs d\u0026rsquo;étendre leur réseau local vers le cloud AWS.\nCaractéristiques clés   Connectivité Sécurisée : AWS VPN utilise des protocoles de sécurité tels que IPSec (Internet Protocol Security) pour assurer une connexion sécurisée et chiffrée entre les locaux de l\u0026rsquo;entreprise et le cloud AWS.\n  Options de Connexion : AWS propose deux options principales de VPN : AWS Site-to-Site VPN pour connecter l\u0026rsquo;infrastructure sur site à un VPC (Virtual Private Cloud) AWS, et AWS Client VPN pour permettre aux utilisateurs distants de se connecter au réseau VPC.\n  Intégration avec VPC : AWS VPN s\u0026rsquo;intègre directement avec les VPC, permettant aux entreprises de créer des connexions privées entre leur réseau local et des réseaux virtuels AWS.\n  Chiffrement Fort : Les connexions VPN sont sécurisées grâce à des algorithmes de chiffrement forts, garantissant la confidentialité et l\u0026rsquo;intégrité des données transitant entre les réseaux.\n  Scalabilité : AWS VPN est conçu pour être hautement évolutif, permettant aux entreprises d\u0026rsquo;ajuster la capacité de leur connexion en fonction des besoins de leur réseau.\n  Monitoring et Logging : Le service offre des outils de surveillance et de journalisation pour permettre aux administrateurs de suivre l\u0026rsquo;utilisation de la connexion VPN, les performances et les éventuels problèmes.\n  Prise en Charge de Connexions Redondantes : AWS VPN permet la configuration de connexions redondantes pour améliorer la disponibilité et la résilience de la connectivité.\n  Utilisations Courantes   Extension du Réseau Local : AWS VPN est utilisé pour étendre le réseau local d\u0026rsquo;une entreprise vers le cloud AWS, permettant aux ressources sur site d\u0026rsquo;accéder aux services AWS de manière sécurisée.\n  Connexion d\u0026rsquo;Utilisateurs Distants : AWS Client VPN est utilisé pour permettre aux utilisateurs distants de se connecter au réseau VPC de l\u0026rsquo;entreprise de manière sécurisée.\n  Besoins de Sécurité Élevés : Il est utilisé dans les situations où des exigences de sécurité élevées imposent l\u0026rsquo;utilisation d\u0026rsquo;une connexion VPN chiffrée pour les transferts de données.\n  Accès à des Ressources AWS Spécifiques : AWS VPN permet d\u0026rsquo;accéder de manière sécurisée à des ressources spécifiques hébergées dans AWS sans utiliser une connexion internet publique.\n  En résumé, AWS VPN fournit une solution sécurisée et évolutive pour établir des connexions réseau entre les locaux de l\u0026rsquo;entreprise et le cloud AWS, offrant une connectivité privée et chiffrée pour répondre aux besoins de sécurité et de performance.\nComparaison AWS Direct Connect et AWS VPN AWS API Gateway API Gateway is a fully managed service that makes it easy for developers to publish, maintain, monitor, and secure application programming interfaces at any scale. It acts as a “front door” for applications to access data, business logic, or functionality from your back-end services.\nAPI Gateway allows you to build and manage APIs:\n Share data between systems Integrate with services like lambda  AWS API Gateway est un service d\u0026rsquo;Amazon Web Services (AWS) qui permet aux développeurs de créer, déployer et gérer des API (Interfaces de Programmation d\u0026rsquo;Applications) de manière scalable et sécurisée. C\u0026rsquo;est un service entièrement géré qui simplifie le processus de création d\u0026rsquo;API pour les applications et les services, offrant des fonctionnalités telles que la gestion du trafic, la sécurité, la surveillance et la génération de documentation.\nCaractéristiques Clés   Création d\u0026rsquo;API :\n AWS API Gateway permet aux développeurs de créer des API RESTful ou WebSocket pour leurs applications, fournissant un point de terminaison central pour l\u0026rsquo;accès aux fonctionnalités backend.    Déploiement Simple :\n Facilite le déploiement des API, offrant des options pour déployer sur plusieurs environnements, créer des versions et mettre en œuvre des stratégies de déploiement canari.    Gestion du Trafic :\n Permet de contrôler et de gérer le trafic API, avec des fonctionnalités telles que le contrôle du débit, la limitation du nombre de requêtes, la mise en cache et la gestion des versions.    Sécurité :\n Offre des fonctionnalités avancées de sécurité, y compris l\u0026rsquo;authentification des utilisateurs, la gestion des autorisations, la prise en charge d\u0026rsquo;OAuth, et la possibilité d\u0026rsquo;intégrer avec AWS Identity and Access Management (IAM).    Transformation des Données :\n Permet la transformation des données à la volée, ce qui facilite l\u0026rsquo;intégration avec différents backends en convertissant automatiquement les formats de données.    Monitoring et Journalisation :\n Intègre des outils de surveillance avancés, notamment AWS CloudWatch, pour suivre les performances, surveiller les erreurs et générer des journaux détaillés.    Intégration avec d\u0026rsquo;Autres Services AWS :\n S\u0026rsquo;intègre étroitement avec d\u0026rsquo;autres services AWS tels que AWS Lambda, Amazon S3, AWS Step Functions, et d\u0026rsquo;autres, permettant la construction d\u0026rsquo;architectures serverless.    Génération de Documentation :\n Fournit automatiquement une documentation pour les API créées, facilitant leur utilisation par d\u0026rsquo;autres développeurs et équipes.    Personnalisation :\n Permet la personnalisation des paramètres tels que les noms de domaine personnalisés, les certificats SSL et les stratégies de gestion des API.    Utilisations Courantes   Exposition d\u0026rsquo;API : Utilisé pour exposer des services backend et des fonctionnalités sous forme d\u0026rsquo;API accessibles via Internet.\n  Création de Passerelles d\u0026rsquo;API : Facilite la création de passerelles pour permettre aux clients d\u0026rsquo;accéder à plusieurs services backend via une seule API.\n  Gestion du Trafic : Utilisé pour gérer le trafic, contrôler l\u0026rsquo;accès aux ressources, et mettre en œuvre des politiques de sécurité.\n  Création d\u0026rsquo;Applications Serverless : Intégré avec AWS Lambda pour la création d\u0026rsquo;applications serverless sans provisionnement ni gestion d\u0026rsquo;infrastructure.\n  Développement d\u0026rsquo;API pour le Mobile : Souvent utilisé pour créer des API destinées aux applications mobiles, facilitant l\u0026rsquo;accès aux fonctionnalités backend.\n  AWS API Gateway simplifie le processus de création, de déploiement et de gestion d\u0026rsquo;API, permettant aux développeurs de se concentrer sur la création de fonctionnalités plutôt que sur la gestion de l\u0026rsquo;infrastructure sous-jacente.\nTime to remember when Studying for the Exam Databases Liens :\n https://my.visme.co/view/768ypr67-s03-l12-utilizing-databases  Amazon Relational Database Service (RDS) Amazon Relational Database Service (RDS) :\n Support popular DB Engines Offers HA and fault tolerance using multi-az deployment option AWS MAnages the DB with automatic sw patching, backups, system maintenance, and more Read replicas across regions in order to provide enhanced performance and durability  Amazon Relational Database Service (RDS) est un service de gestion de bases de données relationnelles dans le cloud proposé par Amazon Web Services (AWS). Il offre une solution entièrement gérée pour déployer, exploiter et évoluer des bases de données relationnelles, éliminant ainsi la complexité liée à la configuration, à la maintenance et à la sauvegarde des bases de données traditionnelles.\nCaractéristiques Clés   Prise en Charge de Divers Moteurs de Bases de Données :\n Amazon RDS prend en charge plusieurs moteurs de bases de données relationnelles, notamment MySQL, PostgreSQL, MariaDB, Oracle, et Microsoft SQL Server.    Facilité de Déploiement :\n Permet de déployer rapidement une base de données relationnelle en quelques clics via la console AWS ou à l\u0026rsquo;aide d\u0026rsquo;outils de ligne de commande.    Automatisation des Tâches d\u0026rsquo;Administration :\n Automatise les tâches administratives telles que les mises à jour de base de données, les sauvegardes régulières, la surveillance des performances et la gestion des correctifs de sécurité.    Scalabilité :\n Offre des options de scalabilité automatique pour ajuster les ressources de calcul et de stockage en fonction des besoins de l\u0026rsquo;application.    Haute Disponibilité et Tolérance aux Pannes :\n Propose des fonctionnalités de réplication multi-région, de création de répliques de lecture et de sauvegardes automatisées pour garantir une haute disponibilité et la résilience aux pannes.    Sécurité Intégrée :\n Intègre des fonctionnalités de sécurité avancées telles que le chiffrement des données au repos et en transit, la gestion des clés de chiffrement, et l\u0026rsquo;intégration avec AWS Identity and Access Management (IAM).    Surveillance et Alertes :\n Offre des outils de surveillance, de journalisation et de génération d\u0026rsquo;alertes via Amazon CloudWatch, permettant aux utilisateurs de suivre les performances de la base de données.    Intégration avec AWS Services :\n S\u0026rsquo;intègre de manière transparente avec d\u0026rsquo;autres services AWS tels que Amazon VPC, AWS Secrets Manager, AWS CloudFormation, et plus encore.    Utilisations Courantes   Applications Web :\n Idéal pour les applications web nécessitant une base de données relationnelle, offrant une gestion facile et une évolutivité selon les besoins.    Applications d\u0026rsquo;Entreprise :\n Souvent utilisé pour les applications d\u0026rsquo;entreprise nécessitant une gestion de base de données relationnelle, une haute disponibilité et une sécurité renforcée.    Développement et Test :\n Pratique pour les environnements de développement et de test, offrant la possibilité de créer rapidement des bases de données et de les supprimer une fois le développement terminé.    Analyse de Données :\n Utilisé pour les bases de données nécessaires à l\u0026rsquo;analyse de données et aux rapports, avec la possibilité de créer des répliques de lecture pour améliorer les performances.    Amazon RDS simplifie le processus de gestion des bases de données relationnelles, permettant aux développeurs et aux entreprises de se concentrer sur le développement d\u0026rsquo;applications plutôt que sur l\u0026rsquo;infrastructure sous-jacente des bases de données.\nAmazon Aurora Amazon Aurora is a relational database compatible with MySQL and PostgreSQL that was created by AWS :\n MySQL and PostgreSQL faster than normal MySQL and PostgreSQL Scales automatically Managed by RDS  Amazon Aurora est un service de base de données relationnelle entièrement géré proposé par Amazon Web Services (AWS). Il offre une solution de base de données relationnelle compatible avec MySQL et PostgreSQL, conçue pour être hautement performante, évolutive et résiliente. Aurora combine les avantages des bases de données relationnelles traditionnelles avec les avantages de l\u0026rsquo;infrastructure cloud, offrant ainsi une solution efficace pour les applications nécessitant une base de données relationnelle.\nCaractéristiques Clés   Compatibilité avec MySQL et PostgreSQL :\n Aurora est compatible avec les moteurs de bases de données MySQL et PostgreSQL, permettant une migration facile des applications existantes utilisant ces moteurs.    Performance Élevée :\n Offre des performances élevées avec une latence faible, adaptée aux charges de travail intensives en lecture/écriture et aux applications nécessitant des temps de réponse rapides.    Réplication Multi-Région :\n Propose la réplication multi-région, permettant de créer des répliques de bases de données dans différentes régions pour améliorer la disponibilité et la tolérance aux pannes.    Scalabilité Automatique :\n Permet la scalabilité automatique en ajustant automatiquement les ressources de calcul et de stockage en fonction de la charge de travail, offrant ainsi une flexibilité pour les applications en évolution.    Haute Disponibilité :\n Aurora est conçu pour une haute disponibilité avec une réplication automatisée des données sur plusieurs zones de disponibilité, assurant une continuité de service même en cas de défaillance d\u0026rsquo;une zone.    Sauvegardes Automatiques :\n Effectue des sauvegardes automatiques régulières, permettant de restaurer la base de données à un point antérieur en cas de besoin.    Sécurité Intégrée :\n Intègre des fonctionnalités de sécurité avancées telles que le chiffrement des données au repos et en transit, la gestion des clés de chiffrement, et l\u0026rsquo;intégration avec AWS Identity and Access Management (IAM).    Intégration avec AWS Services :\n S\u0026rsquo;intègre de manière transparente avec d\u0026rsquo;autres services AWS tels que Amazon CloudWatch, AWS Identity and Access Management, AWS Key Management Service, etc.    Utilisations Courantes   Applications Web Haute Performance :\n Idéal pour les applications web nécessitant des performances élevées, une faible latence et une évolutivité automatique.    Applications d\u0026rsquo;Entreprise :\n Souvent utilisé pour les applications d\u0026rsquo;entreprise critiques nécessitant une base de données relationnelle hautement disponible et performante.    Migration depuis MySQL/PostgreSQL :\n Convient pour les entreprises souhaitant migrer leurs bases de données MySQL ou PostgreSQL vers le cloud AWS sans modifier le code d\u0026rsquo;application.    Applications avec des Besoins de Réplication Multi-Région :\n Approprié pour les applications nécessitant une réplication de données multi-région pour améliorer la résilience aux pannes et la disponibilité.    Amazon Aurora offre une alternative performante et évolutive aux bases de données relationnelles traditionnelles, avec des fonctionnalités avancées pour répondre aux besoins des applications modernes hébergées dans le cloud AWS.\nAmazon DynamoDB Amazon DynamoDB is a fully managed NoSQL key-value and document database :\n NoSQL k/v DB Fully managed and serverless Non-relational Scales automatically to massive worklaods with fast performance  Amazon DynamoDB est un service de base de données NoSQL entièrement géré proposé par Amazon Web Services (AWS). Il offre une solution de stockage de données hautement disponible, scalable et sans serveur, conçue pour des applications nécessitant des performances rapides et une gestion flexible des données. DynamoDB est adapté aux charges de travail à grande échelle avec des besoins de lecture et d\u0026rsquo;écriture intensifs.\nCaractéristiques Clés   Base de Données NoSQL :\n DynamoDB est une base de données NoSQL qui prend en charge les modèles de données clé-valeur et de documents, offrant ainsi une flexibilité pour modéliser les données selon les besoins.    Entièrement Géré :\n AWS DynamoDB est un service entièrement géré, ce qui signifie qu\u0026rsquo;AWS prend en charge la gestion de l\u0026rsquo;infrastructure, la mise à l\u0026rsquo;échelle automatique, les mises à jour de logiciels et la gestion des performances.    Scalabilité Automatique :\n DynamoDB permet de faire évoluer automatiquement la capacité de stockage et le débit en fonction des besoins de l\u0026rsquo;application, assurant ainsi des performances constantes même avec une charge de travail variable.    Haute Disponibilité :\n Le service offre une haute disponibilité en répartissant les données de manière automatique et redondante sur plusieurs centres de données AWS.    Modèle de Consistance Configurable :\n DynamoDB propose plusieurs modèles de consistance, y compris une consistance forte et éventuelle, permettant aux utilisateurs de choisir la meilleure option en fonction de leurs besoins.    Sécurité Intégrée :\n Intègre des fonctionnalités de sécurité avancées, telles que le chiffrement des données au repos et en transit, la gestion des autorisations avec AWS Identity and Access Management (IAM), et la possibilité de définir des filtres de sécurité.    Intégration avec AWS Services :\n S\u0026rsquo;intègre de manière transparente avec d\u0026rsquo;autres services AWS tels que AWS Lambda, Amazon S3, Amazon Kinesis, et plus encore, permettant une intégration facile dans des architectures cloud complexes.    Gestion de Versions et de Backups :\n Offre la possibilité de gérer des versions de données et de créer des backups continus, permettant de restaurer des données à des points antérieurs.    Utilisations Courantes   Applications Web et Mobiles :\n Idéal pour les applications web et mobiles nécessitant une base de données flexible, scalable et à haute performance.    Applications IoT (Internet des Objets) :\n Adapté aux applications IoT qui génèrent de grandes quantités de données avec des besoins de traitement rapide.    Systèmes de Gestion de Sessions :\n Souvent utilisé pour gérer les sessions utilisateur dans des environnements sans serveur et à grande échelle.    Systèmes de Gestion de Contenu :\n Approprié pour les systèmes de gestion de contenu nécessitant une gestion flexible des données non structurées.    Amazon DynamoDB offre une solution performante et scalable pour les applications modernes qui nécessitent une gestion flexible des données avec une faible latence et une haute disponibilité. Son modèle de tarification pay-as-you-go le rend adapté à une variété de cas d\u0026rsquo;utilisation.\nAmazon DocumentDB Amazon DocumentDB is a fully managed document database that supports MongoDB :\n Document DB MongoDB compatible Fully managed and serverless Non-relational  Amazon DocumentDB est un service de base de données NoSQL entièrement géré par Amazon Web Services (AWS) qui prend en charge le modèle de données de documents. Il est compatible avec MongoDB, ce qui signifie qu\u0026rsquo;il offre une interface de programmation (API) compatible avec MongoDB, permettant aux applications MongoDB existantes de migrer facilement vers DocumentDB sans nécessiter de modifications significatives du code.\nCaractéristiques Clés   Compatibilité avec MongoDB :\n DocumentDB est compatible avec MongoDB, ce qui signifie qu\u0026rsquo;il prend en charge le langage de requête MongoDB, les pilotes, les outils et les écosystèmes d\u0026rsquo;application, facilitant la migration des applications MongoDB vers DocumentDB.    Entièrement Géré :\n DocumentDB est un service entièrement géré par AWS, ce qui libère les utilisateurs de la gestion opérationnelle de la base de données, y compris les tâches de sauvegarde, de mise à l\u0026rsquo;échelle, de surveillance et de maintenance.    Haute Disponibilité et Durabilité :\n Offre une haute disponibilité avec la réplication automatisée des données sur plusieurs zones de disponibilité. La durabilité des données est assurée grâce à la création automatique de sauvegardes continues.    Scalabilité Horizontale :\n Permet une scalabilité horizontale en ajoutant de manière transparente de nouveaux nœuds à un cluster DocumentDB pour répondre à des charges de travail plus importantes.    Sécurité Intégrée :\n Intègre des fonctionnalités de sécurité avancées, telles que le chiffrement des données au repos et en transit, la gestion des autorisations avec AWS Identity and Access Management (IAM), et la possibilité de définir des règles de pare-feu.    Performances Élevées :\n DocumentDB offre des performances élevées pour les opérations de lecture et d\u0026rsquo;écriture, avec la possibilité de créer des index pour optimiser les requêtes.    Intégration avec AWS Services :\n S\u0026rsquo;intègre de manière transparente avec d\u0026rsquo;autres services AWS, tels que Amazon CloudWatch pour la surveillance et AWS Identity and Access Management (IAM) pour la gestion des autorisations.    Utilisations Courantes   Migration d\u0026rsquo;Applications MongoDB :\n Convient aux entreprises utilisant MongoDB et souhaitant migrer vers un service cloud géré sans nécessiter de modifications importantes de leur code d\u0026rsquo;application.    Applications Web et Mobiles :\n Idéal pour les applications nécessitant un stockage de données flexible avec une compatibilité MongoDB.    Développement Rapide :\n Approprié pour les projets nécessitant une base de données flexible avec une évolutivité rapide.    Applications avec des Modèles de Données de Documents :\n Convient aux applications où le modèle de données de documents est plus approprié, avec des données semi-structurées ou non structurées.    Amazon DocumentDB offre une alternative performante et compatible avec MongoDB pour les applications nécessitant un stockage de données de documents flexible et hautement disponible, avec la facilité de migration depuis MongoDB.\nAmazon ElastiCache Amazon ElastiCache is a fully managed in-memory datastore compatible with Redis or Memcached :\n In-memory datastore compatible with redis or memcached engines data can be lost Offers high performance and low latency  Amazon ElastiCache est un service entièrement géré par Amazon Web Services (AWS) qui permet le déploiement, la gestion et la mise à l\u0026rsquo;échelle de caches en mémoire distribués. Il prend en charge deux moteurs de cache populaires : Redis et Memcached. ElastiCache est conçu pour améliorer les performances des applications en stockant des données fréquemment utilisées en mémoire, réduisant ainsi la latence et améliorant la capacité de réponse.\nCaractéristiques Clés   Moteurs de Cache Pris en Charge :\n ElastiCache prend en charge les moteurs de cache Redis et Memcached, offrant ainsi une flexibilité pour choisir le moteur qui convient le mieux aux besoins de l\u0026rsquo;application.    Entièrement Géré :\n AWS ElastiCache est un service entièrement géré, ce qui signifie qu\u0026rsquo;AWS s\u0026rsquo;occupe des tâches opérationnelles telles que la configuration, la mise à l\u0026rsquo;échelle, la surveillance, les correctifs de sécurité et les sauvegardes.    Mise en Caché Distribuée :\n Permet le déploiement de caches en mémoire distribués sur plusieurs nœuds, améliorant la capacité de stockage et la résilience aux pannes.    Haute Disponibilité :\n Offre la possibilité de configurer des clusters Multi-AZ pour garantir une haute disponibilité, avec une réplication des données entre les zones de disponibilité.    Scalabilité :\n Permet d\u0026rsquo;ajuster dynamiquement la capacité de stockage en ajoutant ou en supprimant des nœuds au cluster, garantissant ainsi une adaptation aux changements de charge.    Intégration avec AWS Services :\n S\u0026rsquo;intègre de manière transparente avec d\u0026rsquo;autres services AWS tels que Amazon CloudWatch pour la surveillance, AWS Identity and Access Management (IAM) pour la gestion des autorisations, et AWS CloudFormation pour l\u0026rsquo;automatisation du déploiement.    Sécurité :\n Intègre des fonctionnalités de sécurité telles que le chiffrement des données en transit et au repos, la gestion des groupes de sécurité, et la possibilité de définir des politiques d\u0026rsquo;accès.    Utilisations Courantes   Amélioration des Performances des Applications Web :\n Idéal pour les applications web nécessitant une amélioration significative des performances en stockant en mémoire des données fréquemment utilisées.    Caching des Résultats de Base de Données :\n Souvent utilisé pour mettre en cache les résultats de requêtes de base de données fréquemment exécutées, réduisant ainsi la charge sur la base de données.    Systèmes de Gestion de Session :\n Approprié pour la gestion de sessions utilisateur dans les applications web, améliorant la réactivité et la scalabilité.    Réduction de la Latence dans les Applications en Temps Réel :\n Convient aux applications nécessitant une faible latence pour les opérations en temps réel, comme les jeux en ligne ou les applications de streaming.    Équivalents Open Source   Redis :\n Équivalent open source pour Redis, le moteur de cache pris en charge par ElastiCache, est Redis. Redis est une base de données en mémoire open source utilisée comme cache, stockage de base de données, et courtier de messages.    Memcached :\n Pour Memcached, une alternative open source est Memcached. Memcached est un système de mise en cache distribué en mémoire utilisé pour accélérer les applications en stockant des portions de données fréquemment utilisées en mémoire.    Amazon ElastiCache offre une solution efficace pour améliorer les performances des applications en utilisant des caches en mémoire distribués, avec la simplicité de gestion offerte par un service cloud entièrement géré.\nAWS Neptune AWS Neptune is a fully managed graph database that supports highly connected datasets :\n Graph DB service Supports highly connected datasets like social media networks Fully managed and serverless  AWS Neptune est un service de base de données de graphe entièrement géré par Amazon Web Services (AWS). Il prend en charge les bases de données de graphe orientées propriétés en utilisant les modèles de données Property Graph et RDF (Resource Description Framework). Neptune est conçu pour stocker et interroger des données hautement connectées, telles que les réseaux sociaux, les recommandations de produits, et les graphes de connaissances.\nCaractéristiques Clés   Modèles de Données Supportés :\n Prend en charge les modèles de données Property Graph et RDF, offrant ainsi une flexibilité pour modéliser des données dans des domaines variés.    Entièrement Géré :\n AWS Neptune est entièrement géré, ce qui signifie qu\u0026rsquo;AWS s\u0026rsquo;occupe de toutes les tâches opérationnelles, y compris la configuration, la mise à l\u0026rsquo;échelle, la sauvegarde et la restauration.    Haute Disponibilité :\n Offre la possibilité de configurer des clusters Multi-AZ pour garantir une haute disponibilité avec la réplication des données sur plusieurs zones de disponibilité.    Sécurité Intégrée :\n Intègre des fonctionnalités de sécurité avancées, telles que le chiffrement des données au repos, la gestion des accès avec AWS Identity and Access Management (IAM), et la possibilité de définir des groupes de sécurité.    Évolutivité Horizontale :\n Permet d\u0026rsquo;ajuster dynamiquement la capacité de stockage et de calcul en ajoutant ou en supprimant des nœuds au cluster Neptune, offrant ainsi une évolutivité horizontale.    Intégration avec AWS Services :\n S\u0026rsquo;intègre de manière transparente avec d\u0026rsquo;autres services AWS tels que Amazon CloudWatch pour la surveillance et AWS CloudTrail pour l\u0026rsquo;audit des activités.    Langages de Requête Standard :\n Prend en charge des langages de requête standard tels que SPARQL (pour les graphes RDF) et Gremlin (pour les graphes Property Graph).    Utilisations Courantes   Réseaux Sociaux et Recommandations :\n Idéal pour modéliser des relations complexes dans les réseaux sociaux et pour générer des recommandations personnalisées.    Graphes de Connaissances :\n Approprié pour la création de graphes de connaissances, stockant des informations interconnectées pour des domaines tels que la recherche en sciences, la biologie, ou la gestion des connaissances.    Analyse de Liens :\n Convient pour l\u0026rsquo;analyse des liens dans des données interconnectées, comme l\u0026rsquo;analyse des dépendances dans les réseaux logistiques ou les relations entre les entités dans une base de données de fraude.    Recherche d\u0026rsquo;Informations :\n Souvent utilisé pour la recherche d\u0026rsquo;informations dans des bases de données complexes où les relations entre les entités sont cruciales.    Équivalents Open Source   GraphDB :\n Un équivalent open source à Neptune pour les graphes RDF est GraphDB, qui prend en charge SPARQL et offre une gestion des données RDF.    JanusGraph :\n Pour les graphes Property Graph, JanusGraph est une alternative open source qui prend en charge le langage de requête Gremlin.    AWS Neptune offre une solution entièrement gérée pour les bases de données de graphe, facilitant le stockage et l\u0026rsquo;interrogation de données hautement connectées dans divers domaines d\u0026rsquo;application.\nUses cases Time to remember when Studying for the Exam Exploring Migration and Transfer Services Liens :\n https://my.visme.co/view/mxzm86mw-s03-l13-exploring-migration-and-transfer-services https://docs.aws.amazon.com/prescriptive-guidance/latest/migration-sql-server/heterogeneous-migration.html https://docs.aws.amazon.com/prescriptive-guidance/latest/migration-sql-server/homogeneous-migration.html https://docs.aws.amazon.com/prescriptive-guidance/latest/migration-oracle-database/welcome.html https://docs.aws.amazon.com/prescriptive-guidance/latest/migration-oracle-database/homogeneous-migration.html https://aws.amazon.com/fr/cloud-adoption-framework/  AWS Database Migration Service (DMS) AWS Database Migration Service (AWS DMS) helps you migrate databases to AWS quickly and securely over the internet. The source database remains fully operational during the migration, minimizing downtime to applications that rely on the database. The AWS Database Migration Service can migrate your data to and from the most widely used commercial and open-source databases.\nDMS helps you migrate databases to or within AWS.\nAWS Database Migration Service (AWS DMS) est un service entièrement géré par Amazon Web Services qui facilite la migration de bases de données relationnelles vers et depuis le cloud AWS, ainsi que d\u0026rsquo;une base de données à une autre. Il prend en charge divers moteurs de bases de données, tels que MySQL, PostgreSQL, Oracle, Microsoft SQL Server, et d\u0026rsquo;autres.\nCaractéristiques Clés   Migrations Homogènes et Hétérogènes :\n Prend en charge les migrations de bases de données homogènes (par exemple, MySQL vers MySQL) et hétérogènes (par exemple, Oracle vers MySQL).    Réplication Continue :\n Permet la réplication continue des données entre la source et la cible pendant la migration, minimisant ainsi le temps d\u0026rsquo;arrêt.    Transformation de Schéma :\n Facilite la transformation des schémas de bases de données lors des migrations, permettant d\u0026rsquo;adapter la structure de la base de données à la cible.    Migration de Données en Temps Réel :\n Permet la migration de données en temps réel, avec une faible latence pour garantir la cohérence des données.    Intégration avec AWS Schema Conversion Tool (SCT) :\n S\u0026rsquo;intègre avec AWS Schema Conversion Tool pour automatiser la conversion du schéma de la base de données source au format compatible avec la base de données cible.    Surveillance et Suivi :\n Offre des fonctionnalités de surveillance en temps réel via Amazon CloudWatch, permettant de suivre les performances et les métriques de migration.    Sécurité :\n Intègre des fonctionnalités de sécurité telles que le chiffrement des données en transit et au repos, la gestion des accès avec AWS Identity and Access Management (IAM), et la possibilité de définir des paramètres de sécurité spécifiques.    Utilisations Courantes   Migration vers AWS RDS ou Aurora :\n Facilite la migration de bases de données vers les services de base de données managés d\u0026rsquo;AWS tels que Amazon RDS ou Amazon Aurora.    Migrations entre Bases de Données On-Premises :\n Approprié pour les migrations entre bases de données on-premises, facilitant le déplacement vers le cloud.    Réplication Continue pour la Business Intelligence :\n Souvent utilisé pour la réplication continue de données pour les analyses en temps réel ou la business intelligence.    Mises à Niveau de Versions de Bases de Données :\n Convient pour les mises à niveau de versions de bases de données, permettant de migrer vers des versions plus récentes sans interruption de service.    Équivalents Open Source   Flyway :\n Flyway est un outil open source de migration de bases de données qui prend en charge la migration de schémas et de données.    Liquibase :\n Liquibase est un autre outil open source de gestion des migrations de bases de données qui permet de définir les changements de schéma de manière déclarative.    AWS Database Migration Service (AWS DMS) simplifie le processus de migration des bases de données avec une approche entièrement gérée. Pour des solutions open source, Flyway et Liquibase sont des alternatives populaires pour la gestion des migrations de bases de données.\nAWS Server Migration Service (SMS) SMS allows you to migrate on-premises servers to AWS\nAWS Server Migration Service (SMS) est un service d\u0026rsquo;Amazon Web Services qui simplifie la migration des charges de travail existantes vers le cloud AWS. Il permet la migration de machines virtuelles (VMs) de diverses plates-formes, y compris VMware, Microsoft Hyper-V, et des serveurs physiques, vers des instances Amazon EC2.\nCaractéristiques Clés   Migrations en Temps Réel :\n Permet la migration en temps réel des charges de travail, minimisant ainsi les temps d\u0026rsquo;arrêt.    Réplication Continue :\n Propose une réplication continue des données, garantissant que la source et la cible restent synchronisées pendant le processus de migration.    Automatisation :\n Automatise de nombreuses tâches liées à la migration, comme la conversion des disques, la configuration des instances EC2, et la mise en place des réseaux.    Intégration avec AWS Mgn :\n S\u0026rsquo;intègre avec AWS Migration Hub et AWS Migration Evaluator pour une gestion centralisée et une évaluation des migrations.    Support pour Diverses Plates-Formes :\n Prend en charge la migration à partir de plates-formes telles que VMware, Microsoft Hyper-V, et des serveurs physiques.    Optimisation de l\u0026rsquo;Infrastructure :\n Propose des fonctionnalités pour l\u0026rsquo;optimisation de l\u0026rsquo;infrastructure, y compris la conversion des types d\u0026rsquo;instances EC2 pour une performance optimale.    Suivi et Surveillance :\n Offre des outils de suivi et de surveillance pour suivre l\u0026rsquo;état de la migration et les performances post-migration.    Utilisations Courantes   Migration de Data Centers :\n Approprié pour la migration de charges de travail à partir de data centers locaux vers le cloud AWS.    Consolidation de Serveurs :\n Souvent utilisé pour la consolidation de serveurs en migrer plusieurs charges de travail vers des instances EC2.    Mises à Niveau de Versions :\n Convient pour les mises à niveau de versions de systèmes d\u0026rsquo;exploitation ou d\u0026rsquo;applications, facilitant la migration vers des environnements plus récents.    Réplication Continue pour la Haute Disponibilité :\n Idéal pour établir une réplication continue pour la haute disponibilité des applications.    Équivalents Open Source   Rsync :\n Rsync est un outil open source de synchronisation de fichiers, qui peut être utilisé pour la migration de données entre serveurs.    Clonezilla :\n Clonezilla est un outil open source de clonage de disques qui peut être utilisé pour créer des images de serveurs et les restaurer sur des machines virtuelles.    AWS Server Migration Service (SMS) offre une solution entièrement gérée pour la migration de serveurs vers le cloud AWS. Pour des alternatives open source, Rsync et Clonezilla peuvent être utilisés pour des scénarios spécifiques de migration de données et de clonage de disques.\nAWS Snow Family Liens :\n https://aws.amazon.com/snow/  La AWS Snow Family est une gamme de services et d\u0026rsquo;appareils physiques proposés par Amazon Web Services pour faciliter le transfert de grandes quantités de données vers et depuis le cloud AWS dans des environnements hors ligne ou à bande passante limitée. Les appareils de la famille Snow incluent AWS Snowcone, AWS Snowball, AWS Snowmobile, et AWS Snowball Edge.\nAWS Snowcone AWS Snowcone est un appareil portable, léger et résistant conçu pour des cas d\u0026rsquo;utilisation sur le terrain, offrant une capacité de stockage de 8 téraoctets et des fonctionnalités de calcul légères. Il peut être utilisé pour collecter, prétraiter et transférer des données vers le cloud AWS.\nAWS Snowball AWS Snowball est un appareil robuste, conçu pour gérer des pétaoctets de données. Il est expédié vers le client, où les données sont transférées, puis l\u0026rsquo;appareil est retourné à AWS. Il peut être utilisé pour des transferts de données importants dans des environnements sans connexion Internet rapide.\nAWS Snowmobile AWS Snowmobile est une solution pour les transferts de données à l\u0026rsquo;échelle du pétaoctet ou de l\u0026rsquo;exaoctet. Il s\u0026rsquo;agit d\u0026rsquo;un conteneur de stockage de données monté sur un camion, permettant de transférer des quantités massives de données vers le cloud AWS de manière sécurisée.\nAWS Snowball Edge AWS Snowball Edge combine les capacités du Snowball avec des fonctionnalités de calcul sur site. Il peut être utilisé pour effectuer des traitements locaux sur les données avant de les transférer vers le cloud, ce qui le rend idéal pour les environnements déconnectés.\nLa famille AWS Snow Family offre des solutions robustes pour le transfert de grandes quantités de données, en particulier dans des environnements difficiles. Les solutions open source sont souvent plus appropriées pour des cas d\u0026rsquo;utilisation plus petits ou des transferts de données en ligne.\nAWS DataSync DataSync allows for online data transfer from on-premises to AWS storage services like S3 or EFS.\nAWS DataSync est un service géré par Amazon Web Services qui facilite le transfert sécurisé et rapide de grandes quantités de données entre les installations locales et les services de stockage cloud, tels que Amazon S3 ou Amazon EFS. Il est conçu pour accélérer et simplifier les transferts de données, optimiser la bande passante, et garantir la cohérence des données.\nCaractéristiques Clés   Transferts Rapides et Parallèles :\n Effectue des transferts de données rapides et parallèles, optimisant l\u0026rsquo;utilisation de la bande passante disponible.    Intégration avec Services AWS :\n S\u0026rsquo;intègre de manière transparente avec Amazon S3, Amazon EFS et d\u0026rsquo;autres services AWS, simplifiant le processus de transfert de données vers et depuis le cloud.    Gestion de Versions :\n Gère automatiquement les versions des fichiers pour garantir la cohérence des données lors des transferts.    Chiffrement des Données :\n Propose des fonctionnalités de chiffrement pour assurer la sécurité des données pendant les transferts et au repos.    Monitoring et Logging :\n Fournit des outils de monitoring via Amazon CloudWatch et génère des journaux d\u0026rsquo;activité pour suivre et analyser les transferts de données.    Gestion de la Bande Passante :\n Permet de définir des limites de bande passante pour s\u0026rsquo;adapter aux exigences spécifiques du réseau.    Utilisations Courantes   Migration de Données :\n Facilite la migration de données massives depuis des centres de données locaux vers le cloud AWS.    Sauvegardes et Restaurations :\n Idéal pour les sauvegardes régulières de données vers le cloud et les restaurations en cas de besoin.    Traitement de Données en Temps Réel :\n Peut être utilisé pour transférer des données en temps réel, par exemple pour le traitement de données en continu.    Distribution de Contenu :\n Approprié pour la distribution rapide de contenu vers différents emplacements.    Équivalents Open Source Bien qu\u0026rsquo;il n\u0026rsquo;existe pas d\u0026rsquo;équivalent open source direct pour AWS DataSync en raison de ses fonctionnalités spécifiques et de son intégration avec les services AWS, certains outils open source peuvent être utilisés pour des scénarios de transfert de données. Parmi eux :\n  Rclone :\n Rclone est un outil en ligne de commande open source qui prend en charge le transfert de données vers et depuis de nombreux services cloud, y compris Amazon S3.    Duplicity :\n Duplicity est un logiciel de sauvegarde open source qui peut être utilisé pour transférer des données de manière sécurisée.    Ces outils open source peuvent être configurés pour des cas d\u0026rsquo;utilisation spécifiques, mais ils peuvent nécessiter plus de configuration manuelle par rapport à la simplicité d\u0026rsquo;utilisation d\u0026rsquo;AWS DataSync.\nTime to remember when Studying for the Exam Leveraging Analytics Services Lien : https://my.visme.co/view/31y6nxm4-s03-l14-leveraging-analytics-services\nAmazon Redshift Redshift is a scalable data warehouse solution.\nAnalytics is the act of querying or processing your data.\nAmazon Redshift est un service de base de données de type entrepôt de données (data warehouse) géré par Amazon Web Services (AWS). Il est conçu pour l\u0026rsquo;analyse rapide de grandes quantités de données à l\u0026rsquo;aide de requêtes SQL, ce qui en fait un choix populaire pour les entreprises cherchant à effectuer des analyses approfondies de leurs données.\nCaractéristiques Clés   Évolutivité Automatique :\n Permet de faire évoluer facilement la capacité de stockage et de calcul en fonction des besoins.    Traitement Massivement Parallèle (MPP) :\n Utilise une architecture MPP pour effectuer des opérations parallèles sur de grandes quantités de données, accélérant ainsi les requêtes.    Compression Automatique :\n Comprime automatiquement les données pour économiser de l\u0026rsquo;espace de stockage et améliorer les performances des requêtes.    Sécurité Intégrée :\n Propose des fonctionnalités de sécurité intégrées, y compris le chiffrement des données au repos et en transit, et l\u0026rsquo;intégration avec AWS Identity and Access Management (IAM).    Intégration avec AWS :\n S\u0026rsquo;intègre facilement avec d\u0026rsquo;autres services AWS tels que Amazon S3, AWS Glue et AWS Lambda pour permettre un flux de données efficace.    Fonctionnalités de Chargement Rapide :\n Offre des fonctionnalités de chargement rapide pour faciliter l\u0026rsquo;importation de grandes quantités de données.    Utilisations Courantes   Analyse de Données :\n Idéal pour l\u0026rsquo;analyse de grandes quantités de données en temps réel.    Rapports et Tableaux de Bord :\n Utilisé pour la création de rapports et de tableaux de bord basés sur des données volumineuses.    Science des Données :\n Populaire parmi les équipes de science des données pour effectuer des analyses avancées.    Stockage de Données Structurées :\n Convient pour le stockage de données structurées provenant de différentes sources.    Équivalents Open Source Bien qu\u0026rsquo;il n\u0026rsquo;existe pas d\u0026rsquo;équivalent open source direct pour Amazon Redshift en raison de ses caractéristiques spécifiques et de son intégration avec d\u0026rsquo;autres services AWS, il existe des alternatives open source pour la création de data warehouses et l\u0026rsquo;analyse de données. Parmi elles :\n  Apache Hive :\n Apache Hive est un projet open source qui fournit un entrepôt de données basé sur Hadoop pour effectuer des requêtes SQL.    Apache Drill :\n Apache Drill est un moteur de requêtes SQL open source qui prend en charge la requête sur des données semi-structurées et non structurées.    Ces solutions open source peuvent être mises en œuvre pour des scénarios de data warehousing, mais elles peuvent nécessiter une configuration et une gestion plus approfondies par rapport à la solution entièrement gérée qu\u0026rsquo;offre Amazon Redshift.\nAmazon Redshift offre une solution puissante et évolutive pour les besoins de data warehousing et d\u0026rsquo;analyse de données dans le cloud. Les équivalents open source peuvent être envisagés en fonction des besoins spécifiques de l\u0026rsquo;entreprise, mais ils nécessitent généralement une gestion plus approfondie et une configuration manuelle.\nAWS Athena AWS Athena is a serverless implementation of Presto. Presto is an interactive query service that allows you to query structured or unstructured data straight out of S3 buckets.\nAWS Athena est un service de requête interactif proposé par Amazon Web Services (AWS) qui permet aux utilisateurs d\u0026rsquo;analyser des données directement stockées dans Amazon S3 en utilisant le langage de requête SQL standard. Il élimine la nécessité de configurer et de gérer une infrastructure de base de données, offrant ainsi une approche serverless pour l\u0026rsquo;analyse de données.\nCaractéristiques Clés   Requêtes SQL Standard :\n Permet aux utilisateurs d\u0026rsquo;écrire des requêtes SQL standard pour analyser les données stockées dans Amazon S3, sans nécessiter de schéma préalable.    Intégration avec Amazon S3 :\n S\u0026rsquo;intègre directement avec Amazon S3, permettant l\u0026rsquo;analyse de données sans nécessiter de chargement préalable dans une base de données.    Approche Serverless :\n N\u0026rsquo;éxige pas la gestion d\u0026rsquo;une infrastructure de base de données, ce qui signifie qu\u0026rsquo;aucun serveur n\u0026rsquo;est à provisionner ou à gérer.    Optimisation Automatique des Requêtes :\n Optimise automatiquement les requêtes pour améliorer les performances, en exploitant les métadonnées et les statistiques de la structure des fichiers stockés dans S3.    Prise en Charge de Formats de Données Multiples :\n Prend en charge plusieurs formats de données tels que CSV, JSON, Apache Parquet, et bien d\u0026rsquo;autres.    Sécurité Intégrée :\n S\u0026rsquo;intègre avec AWS Identity and Access Management (IAM) pour la gestion des autorisations d\u0026rsquo;accès aux données stockées dans S3.    Utilisations Courantes   Analyse Ad Hoc de Données :\n Idéal pour effectuer des analyses ad hoc sur des données stockées dans Amazon S3 sans avoir besoin de préparer une infrastructure.    Exploration de Données :\n Utilisé pour explorer et analyser rapidement de grands ensembles de données stockés dans différents formats.    Tableaux de Bord Interactifs :\n Intégré à des outils de visualisation tels que Amazon QuickSight pour créer des tableaux de bord interactifs.    Analyse de Logs :\n Populaire pour l\u0026rsquo;analyse de logs stockés dans Amazon S3, facilitant la recherche et l\u0026rsquo;analyse de données de journalisation.    Équivalents Open Source Bien que l\u0026rsquo;approche serverless et l\u0026rsquo;intégration transparente avec Amazon S3 rendent Athena unique, certains projets open source peuvent fournir des fonctionnalités similaires dans le contexte d\u0026rsquo;une infrastructure auto-gérée. Parmi eux :\n  PrestoDB :\n PrestoDB est un moteur de requêtes SQL distribué et open source, adapté pour l\u0026rsquo;analyse de données à grande échelle.    Apache Drill :\n Apache Drill offre également une fonctionnalité de requête SQL sur des données semi-structurées et non structurées, bien qu\u0026rsquo;il diffère dans son approche.    AWS Athena reste une solution serverless puissante pour l\u0026rsquo;analyse de données, particulièrement adaptée aux utilisateurs qui veulent tirer parti de leurs données stockées dans Amazon S3 sans avoir à gérer une infrastructure de base de données traditionnelle.\nAWS Glue ETL = Extract Transform and Load\nA key difference between Glue and Athena is that Athena is primarily used as a query tool for analytics and Glue is more of a transformation and data movement tool.\nAWS Glue est un service de préparation et d\u0026rsquo;intégration de données entièrement géré proposé par Amazon Web Services (AWS). Il facilite le processus d\u0026rsquo;extraction, de transformation et de chargement (ETL) des données, permettant aux utilisateurs de préparer et d\u0026rsquo;analyser efficacement leurs ensembles de données pour des analyses ultérieures.\nCaractéristiques Clés   Préparation de Données sans Serveur :\n Permet de créer des tâches ETL sans avoir à provisionner ou gérer une infrastructure, offrant une approche serverless.    Catalogue de Données Intégré :\n Fournit un catalogue de métadonnées intégré qui stocke des informations sur les données sources, facilitant la découverte et l\u0026rsquo;analyse des données.    Transformations Automatiques :\n Propose des transformations de données automatisées basées sur des schémas, réduisant ainsi le besoin de codage manuel.    Intégration avec d\u0026rsquo;Autres Services AWS :\n S\u0026rsquo;intègre nativement avec d\u0026rsquo;autres services AWS tels que Amazon S3, Amazon RDS, Amazon Redshift, et plus encore.    Exploration de Données :\n Permet l\u0026rsquo;exploration interactive des données, facilitant l\u0026rsquo;analyse et la découverte des structures et des schémas.    Planification de Tâches ETL :\n Permet de planifier des tâches ETL récurrentes pour assurer la cohérence et l\u0026rsquo;actualité des données.    Sécurité Intégrée :\n Intègre la sécurité avec AWS Identity and Access Management (IAM) pour gérer les autorisations d\u0026rsquo;accès aux données.    Utilisations Courantes   Transformation de Données :\n Utilisé pour transformer des données brutes en formats appropriés pour l\u0026rsquo;analyse.    Intégration de Données :\n Facilite l\u0026rsquo;intégration de données provenant de sources diverses dans un entrepôt de données centralisé.    Nettoyage et Normalisation :\n Employé pour nettoyer et normaliser les données en préparation pour des analyses ultérieures.    Création de Data Lakes :\n Contribue à la création de data lakes en facilitant l\u0026rsquo;ingestion et la gestion des données brutes.    Équivalents Open Source Bien que la gestion serverless et l\u0026rsquo;intégration transparente avec d\u0026rsquo;autres services AWS soient des caractéristiques spécifiques à AWS Glue, certains outils open source peuvent être utilisés pour des tâches similaires dans des environnements auto-gérés. Parmi eux :\n  Apache NiFi :\n Apache NiFi est un projet open source qui facilite l\u0026rsquo;automatisation du flux de données entre différents systèmes.    Apache Airflow :\n Apache Airflow est une plateforme open source pour orchestrer des workflows de données.    AWS Glue offre une solution entièrement gérée pour la préparation et l\u0026rsquo;intégration de données, adaptée aux organisations cherchant à simplifier le processus ETL sans se soucier de la gestion de l\u0026rsquo;infrastructure sous-jacente.\nAmazon Kinesis Lien(s) :\n https://aws.amazon.com/kinesis/  Amazon Kinesis est une suite de services de streaming de données proposée par Amazon Web Services (AWS) qui permet aux utilisateurs de collecter, traiter et analyser des flux de données en temps réel à grande échelle. La suite Kinesis offre plusieurs services spécialisés pour répondre à des besoins spécifiques liés au traitement des données en streaming.\nAmazon Kinesis Streams Caractéristiques Clés   Collecte de Données en Temps Réel :\n Permet la collecte et la transmission de données en streaming en temps réel.    Évolutivité Automatique :\n S\u0026rsquo;adapte dynamiquement à la charge de données en ajustant automatiquement la capacité de traitement.    Intégration Facile :\n S\u0026rsquo;intègre nativement avec d\u0026rsquo;autres services AWS tels que AWS Lambda, Amazon S3, Amazon Redshift, et bien d\u0026rsquo;autres.    Réplication Multi-Zones :\n Réplique les données de streaming dans plusieurs zones de disponibilité pour assurer la tolérance aux pannes.    Traitement de Données en Temps Réel :\n Permet d\u0026rsquo;appliquer des transformations et des analyses en temps réel sur les données.    Amazon Kinesis Firehose Caractéristiques Clés   Chargement Direct vers AWS :\n Facilite le chargement direct des données de streaming vers d\u0026rsquo;autres services AWS sans nécessiter de configuration complexe.    Intégration Préconfigurée :\n Intègre directement avec des services tels que Amazon S3, Amazon Redshift, Amazon Elasticsearch, et d\u0026rsquo;autres.    Transformation des Données :\n Permet la transformation des données avant de les charger dans la destination finale.    Gestion Automatique de la Capacité :\n Gère automatiquement la capacité en fonction du volume de données, assurant un traitement efficace.    Amazon Kinesis Analytics Caractéristiques Clés   Analyse en Temps Réel :\n Permet l\u0026rsquo;analyse en temps réel des données de streaming à l\u0026rsquo;aide de requêtes SQL standard.    Fonctions SQL Étendues :\n Propose des extensions SQL spécifiques aux données de streaming pour faciliter l\u0026rsquo;analyse.    Intégration avec Kinesis Streams et Firehose :\n S\u0026rsquo;intègre avec les autres services Kinesis pour traiter les données de streaming à différentes étapes du flux.    Utilisations Courantes   Analyse en Temps Réel :\n Utilisé pour l\u0026rsquo;analyse en temps réel des données de capteurs, des logs, des clics d\u0026rsquo;utilisateurs, etc.    Traitement de Flux de Données IoT :\n Appliqué dans le traitement des flux de données générés par les appareils IoT.    Collecte de Logs et de Métriques :\n Employé pour la collecte en temps réel de logs et de métriques de systèmes distribués.    Tableaux de Bord en Temps Réel :\n Utilisé pour créer des tableaux de bord en temps réel basés sur des données de streaming.    Équivalents Open Source Bien que les services Kinesis soient spécifiques à AWS, plusieurs projets open source offrent des fonctionnalités similaires pour la gestion de flux de données en temps réel. Parmi eux :\n  Apache Kafka :\n Apache Kafka est une plateforme open source de gestion de flux de données en temps réel largement utilisée.    Apache Flink :\n Apache Flink est un système de traitement de données en streaming et en batch open source.    Amazon Kinesis offre une solution complète pour la gestion de données en streaming, couvrant la collecte, le traitement et l\u0026rsquo;analyse en temps réel, avec une intégration transparente aux autres services AWS.\nAmazon EMR Amazon Elastic MapReduce (EMR) est un service de traitement de données géré par Amazon Web Services (AWS) qui simplifie le traitement, l\u0026rsquo;analyse et la visualisation de grandes quantités de données en utilisant des frameworks populaires tels que Apache Hadoop, Apache Spark, Apache Hive, Apache HBase, et d\u0026rsquo;autres.\nCaractéristiques Clés   Infrastructure Évolutif :\n Permet de provisionner dynamiquement des clusters avec la capacité de calcul nécessaire pour traiter les charges de travail.    Intégration avec Différents Frameworks :\n S\u0026rsquo;intègre avec une variété de frameworks de traitement de données populaires, offrant une flexibilité dans le choix des outils.    Sécurité Intégrée :\n Intègre des fonctionnalités de sécurité telles que le chiffrement des données au repos et en transit, l\u0026rsquo;intégration avec AWS Identity and Access Management (IAM), et d\u0026rsquo;autres.    Prise en Charge de Différents Types de Données :\n Prend en charge le traitement de différents types de données, y compris des données structurées et non structurées.    Équilibrage Automatique de la Charge :\n Fournit un équilibrage automatique de la charge pour optimiser les performances du cluster.    Gestion Automatisée :\n Automatise la configuration, la gestion, et le dimensionnement du cluster, permettant aux utilisateurs de se concentrer sur leurs tâches de traitement de données.    Utilisations Courantes   Traitement de Données Massives :\n Utilisé pour le traitement de grandes quantités de données nécessitant une infrastructure évolutive.    Analyse de Données Distribuée :\n Appliqué dans des scénarios d\u0026rsquo;analyse distribuée avec des frameworks tels que Apache Spark.    Traitement de Log :\n Employé pour le traitement et l\u0026rsquo;analyse de logs à grande échelle.    Traitement de Données en Temps Réel :\n Utilisé pour le traitement de données en temps réel avec des frameworks comme Apache Flink.    Équivalents Open Source Bien que EMR soit un service managé par AWS, plusieurs projets open source peuvent être utilisés pour des tâches similaires dans des environnements auto-gérés. Parmi eux :\n  Apache Hadoop :\n Apache Hadoop est un framework open source pour le stockage et le traitement distribué de grandes quantités de données.    Apache Spark :\n Apache Spark est un framework open source de traitement de données rapide et généralisé, compatible avec Hadoop.    Amazon Elastic MapReduce (EMR) offre une solution prête à l\u0026rsquo;emploi pour le traitement distribué de données, offrant des avantages de gestion et d\u0026rsquo;intégration avec l\u0026rsquo;écosystème AWS pour les charges de travail de traitement de données à grande échelle.\nAWS Data Pipeline AWS Data Pipeline est un service de transfert et d\u0026rsquo;orchestration de données proposé par Amazon Web Services (AWS). Il permet aux utilisateurs de définir, planifier et automatiser le flux de données entre différents services AWS et sources externes, simplifiant ainsi le traitement et l\u0026rsquo;analyse de données.\nCaractéristiques Clés   Orchestration de Flux de Travail :\n Permet la création et l\u0026rsquo;orchestration de flux de travail de données complexes impliquant plusieurs services et sources de données.    Planification Automatique :\n Facilite la planification automatique des tâches de transfert et de traitement des données selon des horaires prédéfinis.    Intégration avec de Nombreux Services :\n S\u0026rsquo;intègre nativement avec plusieurs services AWS tels que Amazon S3, Amazon RDS, Amazon Redshift, et d\u0026rsquo;autres.    Surveillance et Gestion des Erreurs :\n Offre des fonctionnalités de surveillance et de gestion des erreurs pour garantir la fiabilité des flux de travail.    Support des Données On-Premises :\n Prend en charge le transfert et l\u0026rsquo;orchestration de données à partir de sources on-premises vers des services AWS.    Sécurité Intégrée :\n Intègre la sécurité avec AWS Identity and Access Management (IAM) pour gérer les autorisations d\u0026rsquo;accès aux ressources.    Utilisations Courantes   Transfert de Données Régulier :\n Utilisé pour automatiser le transfert régulier de données entre différents services et systèmes.    Transformation de Données :\n Appliqué dans la transformation de données entre différents formats pour répondre aux besoins d\u0026rsquo;analyse.    Traitement de Flux de Travail Complexes :\n Employé pour orchestrer des flux de travail de données complexes impliquant plusieurs étapes.    Gestion de Données Hybrides :\n Utilisé dans des scénarios où des données doivent être déplacées entre des environnements cloud et on-premises.    Équivalents Open Source Bien que Data Pipeline soit un service managé par AWS, plusieurs projets open source peuvent être utilisés pour des tâches similaires dans des environnements auto-gérés. Parmi eux :\n  Apache Airflow :\n Apache Airflow est une plateforme open source d\u0026rsquo;orchestration de flux de travail qui peut être utilisée pour la gestion de flux de données.    Luigi :\n Luigi est un framework open source pour la construction de pipelines de données complexes.    AWS Data Pipeline offre une solution managée pour l\u0026rsquo;orchestration et le transfert de données, simplifiant la gestion des flux de travail de données entre divers services et sources.\nQuickSight Lien(s) :\n https://aws.amazon.com/quicksight/  Analytics in the Real World Review time  Redshift : a scalable data warehouse solution Athena : a query service for Amazon S3 Glue : prepares the data for analytics Kinesis : analyze data and video streams in real time EMR : helps you process large amounts of data Data Pipeline : helps you move data between compute and storage services running either on AWS or on-premises QuickSight : visualize data using dashboards  Leveraging Machine Learning Services Artificial intelligence (AI) teaches computers to do things that normally require human intelligence.\nAmazon Rekognition Lien :\n https://aws.amazon.com/rekognition/ https://us-east-1.console.aws.amazon.com/rekognition/home?region=us-east-1#/face-comparison  Amazon Rekognition est un service de reconnaissance d\u0026rsquo;images et d\u0026rsquo;analyse vidéo proposé par Amazon Web Services (AWS). Il utilise des modèles d\u0026rsquo;apprentissage automatique pour identifier et analyser des objets, des scènes, des visages, du texte et des activités dans des images et des vidéos.\nCaractéristiques Clés   Détection de Visages :\n Identifie et analyse les visages dans les images, y compris la détection des expressions faciales et des émotions.    Reconnaissance d\u0026rsquo;Objets et de Scènes :\n Permet la reconnaissance d\u0026rsquo;objets et de scènes dans les images, facilitant l\u0026rsquo;analyse contextuelle.    Analyse de Texte dans les Images :\n Détecte et extrait le texte présent dans les images, permettant une compréhension plus approfondie.    Comparaison et Vérification de Visages :\n Permet de comparer des visages pour la vérification d\u0026rsquo;identité et la recherche de similitudes.    Détection d\u0026rsquo;Activités dans les Vidéos :\n Analyse les vidéos pour détecter des activités telles que la marche, la course, et d\u0026rsquo;autres mouvements.    Filtrage de Contenu Inapproprié :\n Utilise des modèles pour filtrer le contenu inapproprié, contribuant à la modération automatique.    Intégration avec d\u0026rsquo;Autres Services AWS :\n S\u0026rsquo;intègre nativement avec d\u0026rsquo;autres services AWS, permettant une utilisation conjointe avec d\u0026rsquo;autres fonctionnalités cloud.    Personnalisation des Modèles :\n Permet la création de modèles personnalisés pour des cas d\u0026rsquo;utilisation spécifiques.    Utilisations Courantes   Sécurité et Surveillance :\n Utilisé dans les systèmes de sécurité pour la détection d\u0026rsquo;intrusion et la surveillance.    Expériences Utilisateur Personnalisées :\n Appliqué pour personnaliser les expériences utilisateur en fonction des émotions détectées.    Gestion de Contenu Média :\n Employé pour la modération de contenu inapproprié dans les médias sociaux et les plateformes en ligne.    Analyse de Vidéos pour les Médias :\n Utilisé dans l\u0026rsquo;analyse automatisée de vidéos pour les médias et la production de contenu.    Équivalents Open Source Bien que Rekognition soit un service managé par AWS, plusieurs projets open source offrent des fonctionnalités similaires de reconnaissance d\u0026rsquo;images. Parmi eux :\n  OpenCV :\n OpenCV est une bibliothèque open source de vision par ordinateur qui propose des fonctionnalités de traitement d\u0026rsquo;images et de reconnaissance faciale.    Dlib :\n Dlib est une bibliothèque open source C++ qui inclut des outils pour la détection et la reconnaissance faciale.    Amazon Rekognition offre une solution puissante et évoluée pour la reconnaissance d\u0026rsquo;images et d\u0026rsquo;activités vidéo, avec des capacités avancées d\u0026rsquo;analyse visuelle basée sur l\u0026rsquo;apprentissage automatique.\nComprehend Lien :\n https://aws.amazon.com/comprehend/  Comprehend is a natural-language processing (NLP) service that finds relationships in text.\nPolly Lien :\n https://aws.amazon.com/polly/  Sagemaker Lien :\n https://aws.amazon.com/sagemaker/  Translate Lien :\n https://aws.amazon.com/translate/  Lex Lien :\n https://aws.amazon.com/lex/  Review Time  Rekognition : allow to automate image and video analysis Comprehend : a NLP service that finds relationships in text Polly : turns text into speech SageMaker : helps build, train and deploy machine learning models quickly Translate : language translation Lex : helm you build conversational interfaces like chatbots  Understanding Developer Tools Cloud9 Lien(s) :\n https://aws.amazon.com/cloud9/  CodeCommit Lien(s) :\n https://aws.amazon.com/codecommit/  CodeCommit is a source control system for private Git repositories (= github).\nCodeBuild Lien(s) :\n https://aws.amazon.com/codebuild/  CodeBuild allows you to build and test your application source code.\nCodeDeploy Lien(s) :\n https://aws.amazon.com/codedeploy/  CodeDeploy manages the deployment of code to compute services in the cloud or on-premises.\nCodePipeline Lien(s) :\n https://aws.amazon.com/codepipeline/  CodePipeline automates the software release process.\nX-Ray Lien(s) :\n https://aws.amazon.com/xray/  X-Ray helps you debug production applications.\nCodeStar Lien(s) :\n https://aws.amazon.com/codestar/  CodeStar helps developers collaboratively work on development projects\nReview time  Cloud9 : write code within an IDE from within web browser CodeCommit : private git repository CodeBuild : build and test application source code CodeDeploy : manages the deployement of code to compute services in the cloud or on-premises CodePipeline : automates the SW release process (dev -\u0026gt; test -\u0026gt; prod) X-Ray : debug productions applications CodeStar : helps dev collaboratively work on dev projects  Exploring Deployment and Infrastructure Management Services These services help you quickly stand up new applications, automate the management of infrastructure, and provide real-time visibility into system health.\nAWS CloudFormation Lien :\n https://aws.amazon.com/cloudformation/  AWS CloudFormation allows you to provision AWS resources using Infrastructure as Code (IaC).\nAWS CloudFormation est un service d\u0026rsquo;Amazon Web Services (AWS) qui permet aux utilisateurs de décrire et de provisionner l\u0026rsquo;infrastructure AWS de manière automatisée et reproductible. Au lieu de créer et de configurer manuellement des ressources individuelles, les utilisateurs peuvent définir leur infrastructure comme du code, utilisant des modèles CloudFormation pour créer et déployer des piles d\u0026rsquo;AWS resources.\nCaractéristiques Clés   Infrastructure en tant que Code (IaC) :\n Permet de décrire l\u0026rsquo;ensemble de l\u0026rsquo;infrastructure AWS souhaitée dans des fichiers de modèle en tant que code.    Modèles Réutilisables :\n Facilite la création de modèles réutilisables pour provisionner rapidement des environnements similaires.    Déploiement et Mise à Jour Automatiques :\n Automatise le déploiement initial des ressources et les mises à jour subséquentes de manière cohérente.    Intégration avec d\u0026rsquo;Autres Services :\n S\u0026rsquo;intègre avec d\u0026rsquo;autres services AWS, permettant l\u0026rsquo;utilisation de CloudFormation avec des services tels que Amazon EC2, Amazon S3, Amazon RDS, et bien d\u0026rsquo;autres.    Gestion des Dépendances :\n Gère automatiquement les dépendances entre les ressources, optimisant l\u0026rsquo;ordre de création et de suppression.    Rollback Automatique en Cas d\u0026rsquo;Échec :\n Effectue un rollback automatique en cas d\u0026rsquo;échec du déploiement pour maintenir l\u0026rsquo;intégrité de la pile.    Gestion des Paramètres :\n Permet la gestion des paramètres pour personnaliser le déploiement en fonction de l\u0026rsquo;environnement.    Visualisation des Ressources :\n Fournit des outils de visualisation pour comprendre la topologie de la pile et les relations entre les ressources.    Utilisations Courantes   Déploiement d\u0026rsquo;Applications :\n Utilisé pour déployer des applications complètes, y compris les ressources nécessaires comme les serveurs, les bases de données, et les services de stockage.    Environnements de Développement et de Test :\n Appliqué pour créer rapidement des environnements de développement et de test conformes aux spécifications.    Automatisation de l\u0026rsquo;Infrastructure :\n Employé pour automatiser la création, la modification et la suppression d\u0026rsquo;infrastructures AWS complexes.    Mise à l\u0026rsquo;Échelle Dynamique :\n Utilisé pour mettre à l\u0026rsquo;échelle dynamiquement l\u0026rsquo;infrastructure en fonction des besoins de charge de travail.    Équivalents Open Source Bien que CloudFormation soit spécifique à AWS, d\u0026rsquo;autres outils open source offrent des fonctionnalités similaires pour l\u0026rsquo;automatisation de l\u0026rsquo;infrastructure, tels que :\n  Terraform :\n Terraform est un outil open source multi-cloud qui permet la gestion de l\u0026rsquo;infrastructure en tant que code, prenant en charge plusieurs fournisseurs de cloud, dont AWS.    Ansible :\n Ansible est une plateforme open source de gestion de configuration et d\u0026rsquo;automatisation qui prend en charge la gestion de l\u0026rsquo;infrastructure.    AWS CloudFormation offre une solution intégrée pour l\u0026rsquo;automatisation de l\u0026rsquo;infrastructure AWS, avec des fonctionnalités avancées pour la gestion et le déploiement automatisé.\nElastic Beanstalk Lien :\n https://aws.amazon.com/elasticbeanstalk/  Elastic Beanstalk allows you to deploy your web applications and web services to AWS.\nAWS OpsWorks Lien :\n https://aws.amazon.com/opsworks/  OpsWorks allows you to use Chef or Puppet to automate the configuration of your servers and deploy code.\nAWS OpsWorks est un service de gestion d\u0026rsquo;infrastructure entièrement géré par Amazon Web Services (AWS). Il permet aux utilisateurs de configurer et de gérer des applications en utilisant des modèles de déploiement automatisés, offrant une solution simplifiée pour l\u0026rsquo;administration des applications et des ressources sous-jacentes.\nCaractéristiques Clés   Gestion des Applications :\n Facilite la gestion des applications en automatisant le déploiement, la configuration et la mise à l\u0026rsquo;échelle.    Modèles de Déploiement :\n Utilise des modèles pour décrire l\u0026rsquo;architecture de l\u0026rsquo;application et les ressources nécessaires.    Prise en Charge de Diverses Applications :\n S\u0026rsquo;adapte à différentes architectures d\u0026rsquo;applications, y compris les applications web, les applications backend, et les applications mobiles.    Gestion des Configurations :\n Permet la gestion des configurations avec la prise en charge de Chef et Puppet pour l\u0026rsquo;automatisation de la configuration.    Déploiement Automatisé :\n Automatise le déploiement des applications avec la possibilité de spécifier des règles de déploiement.    Intégration avec d\u0026rsquo;Autres Services AWS :\n S\u0026rsquo;intègre avec d\u0026rsquo;autres services AWS, tels que Amazon RDS, Amazon S3, et Amazon CloudWatch.    Prise en Charge des Environnements Multi-Couches :\n Gère des applications à plusieurs couches, y compris les serveurs web, les serveurs d\u0026rsquo;application et les bases de données.    Surveillance et Journalisation :\n Fournit des outils de surveillance et de journalisation pour suivre les performances des applications.    Utilisations Courantes   Déploiement d\u0026rsquo;Applications :\n Utilisé pour le déploiement et la gestion d\u0026rsquo;applications web, backend, et mobiles.    Automatisation de la Configuration :\n Appliqué pour automatiser la configuration des instances et des ressources associées.    Mise à l\u0026rsquo;Échelle Automatique :\n Employé pour mettre à l\u0026rsquo;échelle automatiquement les ressources en fonction de la charge de travail.    Gestion des Versions d\u0026rsquo;Applications :\n Utilisé pour gérer les versions des applications et effectuer des déploiements en douceur.    Équivalents Open Source Bien que OpsWorks soit un service managé par AWS, plusieurs outils open source offrent des fonctionnalités similaires pour la gestion d\u0026rsquo;infrastructure, tels que :\n  Chef :\n Chef est un outil open source de gestion de configuration qui permet l\u0026rsquo;automatisation de l\u0026rsquo;infrastructure.    Puppet :\n Puppet est une plateforme open source de gestion de configuration et d\u0026rsquo;automatisation.    AWS OpsWorks offre une solution pratique pour la gestion d\u0026rsquo;infrastructure et le déploiement d\u0026rsquo;applications, avec des fonctionnalités avancées d\u0026rsquo;automatisation et de configuration.\nReview Time Utilizing Messaging and Integration Services: SQS Lien(s) :\n https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/standard-queues.html https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html https://aws.amazon.com/sqs/faqs/  Amazon Simple Queue Service (SQS) Lien :\n https://aws.amazon.com/sqs/  SQS is a message queuing service that allows you to build loosely coupled systems.\nAmazon Simple Queue Service (SQS) est un service de file d\u0026rsquo;attente entièrement géré fourni par Amazon Web Services (AWS). Il permet aux applications distribuées et aux composants de systèmes de communiquer de manière asynchrone et fiable, en utilisant des files d\u0026rsquo;attente pour stocker temporairement les messages.\nCaractéristiques Clés   Communication Asynchrone :\n Permet la communication asynchrone entre les composants d\u0026rsquo;une application ou entre différentes applications.    Fiabilité et Durabilité :\n Assure la fiabilité des messages en les stockant de manière durable, même en cas de défaillance des composants.    Dé-Couplage des Composants :\n Permet de dé-coupler les composants d\u0026rsquo;une application, réduisant la dépendance directe et améliorant la résilience du système.    Évolutivité Automatique :\n Évolutivité automatique pour gérer les pics de charge, avec la possibilité de dimensionner dynamiquement la capacité des files d\u0026rsquo;attente.    Intégration avec d\u0026rsquo;Autres Services AWS :\n S\u0026rsquo;intègre nativement avec d\u0026rsquo;autres services AWS, permettant une intégration facile dans des architectures cloud complexes.    Prise en Charge de Différents Modèles de File d\u0026rsquo;Attente :\n Prise en charge de plusieurs modèles de file d\u0026rsquo;attente, y compris les files standard et les files FIFO (First-In-First-Out).    Sécurité et Contrôle d\u0026rsquo;Accès :\n Offre des fonctionnalités de sécurité avancées, y compris le contrôle d\u0026rsquo;accès basé sur les politiques (IAM) et la confidentialité des données en transit.    Gestion des Messages en Double :\n Pour les files FIFO, garantit l\u0026rsquo;ordre d\u0026rsquo;arrivée des messages et élimine les doublons.    Utilisations Courantes   Dé-Couplage des Services :\n Utilisé pour dé-coupler les services dans une architecture microservices.    Traitement de Tâches Asynchrones :\n Appliqué pour gérer des tâches asynchrones, telles que le traitement d\u0026rsquo;images, l\u0026rsquo;envoi de notifications, etc.    Communication entre Applications :\n Utilisé pour la communication asynchrone entre différentes applications.    File d\u0026rsquo;Attente de Commandes :\n Employé pour la création de file d\u0026rsquo;attente de commandes dans les architectures distribuées.    Équivalents Open Source Bien que SQS soit un service managé par AWS, plusieurs solutions open source offrent des fonctionnalités similaires pour la gestion de file d\u0026rsquo;attente, notamment :\n  RabbitMQ :\n RabbitMQ est une file d\u0026rsquo;attente de messages open source et une solution de messagerie asynchrone.    Apache Kafka :\n Apache Kafka est une plateforme de diffusion de messages distribuée, conçue pour la gestion de flux de données en temps réel.    Amazon Simple Queue Service (SQS) offre une solution robuste et entièrement gérée pour la gestion de file d\u0026rsquo;attente dans des environnements cloud, avec une facilité d\u0026rsquo;utilisation et une intégration étroite avec d\u0026rsquo;autres services AWS.\nReview Time Utilizing Messaging and Integration Services: SNS and SES Simple Notification Service (SNS) Liens:\n https://aws.amazon.com/sns/  Simple Email Service (SES) Liens :\n https://aws.amazon.com/ses/  Review Time Exploring Auditing, Monitoring, and Logging Services Lien(s) :\n https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/monitor_estimated_charges_with_cloudwatch.html#turning_on_billing_metrics  CloudWatch Lien(s) :\n https://aws.amazon.com/cloudwatch/  CloudWatch :\n CloudWatch Alarms CloudWatch Logs CloudWatch Metrics CloudWatch Events  CloudTrail Lien(s) :\n https://aws.amazon.com/cloudtrail/  Review Time Exploring Additional Services Amazon Workspaces Lien(s) :\n https://aws.amazon.com/workspaces/  Amazon Connect Lien(s) :\n https://aws.amazon.com/connect/  Amazon Connect est un service de centre de contact cloud proposé par Amazon Web Services (AWS). Il fournit une solution complète de centre de contact basée sur le cloud, permettant aux entreprises de créer et de gérer facilement des centres de contact virtuels, sans avoir à investir dans des infrastructures matérielles coûteuses.\nCaractéristiques Clés   Centre de Contact Virtuel :\n Permet la création de centres de contact virtuels sans nécessiter d\u0026rsquo;investissements importants en infrastructure physique.    Simplicité d\u0026rsquo;Utilisation :\n Interface utilisateur intuitive et conviviale pour la configuration et la gestion des centres de contact.    Évolutivité Automatique :\n Évolutivité automatique pour faire face aux variations de charge, en ajustant automatiquement les ressources nécessaires.    Intégration avec d\u0026rsquo;Autres Services AWS :\n Intégration native avec d\u0026rsquo;autres services AWS tels que Amazon S3, Amazon DynamoDB, et Amazon Redshift pour une expérience complète.    Analytique Intégrée :\n Fournit des fonctionnalités d\u0026rsquo;analytique intégrées pour surveiller les performances du centre de contact et obtenir des informations exploitables.    Outils de Routage Avancés :\n Des outils avancés de routage des appels pour diriger efficacement les appels vers les agents les mieux adaptés.    Automatisation avec des Bots :\n Intégration de chatbots et d\u0026rsquo;assistants virtuels pour automatiser certaines tâches et fournir une assistance automatisée aux clients.    Flexibilité de Configuration :\n Flexibilité pour configurer des scénarios de centre de contact complexes adaptés aux besoins spécifiques de l\u0026rsquo;entreprise.    Utilisations Courantes   Service Client :\n Utilisé pour gérer les interactions avec les clients, répondre aux questions et résoudre les problèmes.    Support Technique :\n Déployé pour fournir un support technique aux clients, y compris la gestion des tickets d\u0026rsquo;assistance.    Ventes et Marketing :\n Utilisé pour les opérations de vente et de marketing, notamment la gestion des appels de ventes et le suivi des campagnes.    Enquêtes et Retours :\n Mis en place pour mener des enquêtes téléphoniques et gérer les retours des clients.    Équivalents Open Source Amazon Connect étant un service propriétaire d\u0026rsquo;AWS, il n\u0026rsquo;existe pas d\u0026rsquo;équivalent open source direct. Cependant, plusieurs solutions open source offrent des fonctionnalités similaires dans le domaine des centres de contact virtuels, notamment :\n  Asterisk :\n Asterisk est une solution de téléphonie open source qui peut être utilisée pour mettre en place des centres de contact virtuels.    FreePBX :\n FreePBX est une plateforme de gestion de PBX open source qui peut être utilisée pour créer des systèmes de centre de contact.    Amazon Connect est souvent choisi pour sa simplicité d\u0026rsquo;utilisation, son intégration native avec les services AWS, et sa facilité de mise en œuvre sans avoir à gérer l\u0026rsquo;infrastructure sous-jacente.\nReview Time Section Review Lien(s) :\n https://my.visme.co/view/vdky0j4z-s03-l21-section-review  LABs Create a DynamoDB Table Using CloudFormation Source code =\u0026gt; ici.\nCreate a DynamoDB Table Using CloudFormation Security and Compliance  Liens :  https://my.visme.co/view/90mo8w9g-s04-l01-section-introduction-security-amp-compliance    Security Encryption Secrets Management Liens  https://explore.skillbuilder.aws/learn/course/internal/view/elearning/108/aws-well-architected-badge  ","date":"2023-08-06T14:52:59+02:00","image":"https://yilas.github.io/WA-Arch-Blog-logo-1024x576.png","permalink":"https://yilas.github.io/p/aws-certified-cloud-practitioner/","title":"AWS Certified Cloud Practitioner (CLF-C01/CLF-C02))"},{"content":"Introduction  Le cadre AWS Well-Architected Framework décrit les concepts clés, les principes de conception et les bonnes pratiques architecturales pour concevoir et exécuter des charges de travail dans le cloud. En répondant à quelques questions fondamentales, vous découvrez si votre architecture est en harmonie avec les bonnes pratiques cloud et vous recevez des conseils pour vous améliorer.\n Voici les principales caractéristiques du cadre AWS Well-Architected :\n  Les six piliers : Le cadre Well-Architected repose sur six piliers fondamentaux pour l\u0026rsquo;architecture cloud, qui sont l\u0026rsquo;excellence opérationnelle, la sécurité, l\u0026rsquo;efficacité de performance, la fiabilité, l\u0026rsquo;optimisation des coûts et le développement durable. Chaque pilier représente un domaine essentiel à considérer lors de la conception de votre architecture cloud.\n  Ateliers AWS Well-Architected : AWS propose des ateliers où les clients peuvent collaborer avec des architectes AWS certifiés pour examiner leurs charges de travail en cours et les comparer aux meilleures pratiques du cadre Well-Architected. Au cours de ces ateliers, les participants peuvent discuter de leur architecture actuelle, identifier les éventuelles améliorations et recevoir des recommandations personnalisées pour optimiser leur environnement AWS.\n  Questionnaire Well-Architected : Le cadre Well-Architected est également basé sur un questionnaire détaillé qui permet aux clients d\u0026rsquo;évaluer eux-mêmes leurs charges de travail en fonction des six piliers. En répondant aux questions du questionnaire, les utilisateurs peuvent obtenir un aperçu initial de la qualité de leur architecture cloud et identifier les domaines potentiels d\u0026rsquo;amélioration.\n  Ressources et guides : AWS met à disposition de nombreuses ressources, études de cas, guides et documentation sur le cadre Well-Architected. Ces documents offrent des explications détaillées sur chaque pilier, des exemples d\u0026rsquo;architecture, ainsi que des conseils pour optimiser les performances, la sécurité et les coûts de vos solutions cloud.\n  Objectifs  An overview of the AWS Well-Architected (AWS WA) Framework The components of the framework The pillars and general design principles of the framework  AWS Well-Architected Framework Overview A brief history of the Well-Architected Framework Before we dive deeper into the components of the framework, we will take a look at how it started and how it evolved over time. AWS Well-Architected started in 2012.\n In 2013, AWS solutions architects started reviewing customer workloads. In 2014, AWS standardized the questions across four pillars. In 2015, AWS published a formal framework based on the four pillars. We dive deeper into the pillars in a later module of this course. In 2016, we added the operational excellence pillar to the Well-Architected Framework. To scale to more customers, AWS trained select AWS Partners to review customer workloads in 2017. In 2018, the AWS Well-Architected Tool launched in the AWS console making it available to all customers. In 2019, AWS launched the AWS WellArchitected Tool and the Well-Architected Partner Program, in multiple Regions. In 2020, AWS updated the framework, added more lenses, and launched API access to the AWS Well-Architected Tool. In 2021, the framework added the sustainability pillar and additional lenses. In 2022, the AWS WellArchitected Tool launched in AWS GovCloud Regions and the integration with AWS Trusted Advisor. In 2023, Well-Architected continues to add more features, lenses and integrations with other AWS services.  Components of the Well-Architected Framework The Well-Architected Framework is composed of content, tools, and data. The framework includes content that you can use to learn AWS guidelines, such as pillars, design principles, and best practices.\nThe framework also includes the AWS Well-Architected Tool that you can use to measure your workload and teams against these best practices.\nAnother component of the framework is the data that you acquire during the Well-Architected Framework Review of your workloads. You can use this data to continuously improve your workloads and operations.\nIn this module, you will dive deeper into content. You will learn more about the AWS Well-Architected Tool and the Well-Architected Framework Review in future modules.\nWell-Architected Framework content The Well-Architected Framework is a set of questions and design principles across six pillars. Alongside the pillars of the framework are the lenses, which provide guidance with a focus on specific industry or technology domains.\nTo evaluate the health of your workloads, you answer a set of foundational questions, based on the framework, pillars, and lenses. These questions will validate if a certain best practice is in place in the workload or not.\nPillars of AWS Well-Architected There are currently six pillars in the Well-Architected Framework:\n operational excellence, security, reliability, performance efficiency, cost optimization, sustainability.  These pillars are the foundations of the architecture for your technology solutions in the cloud.\nWell-Architected lenses The Well-Architected lenses extend the guidance offered by AWS Well-Architected to specific industry and technology domains. Examples of these domains are machine learning, data analytics, serverless applications, high-performance computing, Internet of Things, SAP, streaming media, the gaming industry, hybrid networking, and financial services.\nTo fully evaluate workloads, you use applicable lenses together with the framework and its six pillars. You can also create user-defined and managed custom lenses to best align with your organization\u0026rsquo;s industry, operational plans, and internal processes. You can create your own question sets and add context and best practices as they relate to your own organization and processes. Not all of the available lenses are in the tool currently, but all lenses are available as part of the framework.\nGeneral design principles General design principles are applied across all workloads and all pillars. There are also design principles that are specific to each pillar, which you will learn more about next.\nCloud computing has opened up the technology space to a whole new world of thinking where constraints we had in the traditional environment no longer exist. When thinking about general design principles, it’s interesting to contrast with how you would think about this in a traditional environment. You would have had to guess how much infrastructure you needed, often based on very high-level business requirements and demand and often before a line of code is written. You could not afford to test at scale because a complete duplicate of production costs is hard to justify, especially with low utilization. So, when you went into production you normally found a whole new class of issues at high scale.\nAny proof of concepts or architectural experimentation was done manually and was usually only done at the start of the project. You had static architectures and it was difficult to even think about making a change. You generally couldn’t generate data sets that made it possible to make informed decisions, so you probably used models and assumptions to size your architecture. Finally, in a traditional environment, you would only exercise your runbook when something bad happened in production.\nIn the cloud, constraints have been removed. You can use these principles to take advantage of that.\nDesign principles Each pillar of the framework has its own design principles as well. These are called pillar-specific design principles and they apply only to specific pillars of the framework.\nAs you learned earlier, one of the general design principles is to improve through game days. Game days is a term that means testing your architecture and processes by regularly simulating events in production. This will help you understand where you can make improvements and can help develop organizational experience in dealing with events.\nAn example for a security pillar design principle is to prepare for security events. Prepare for an incident by having incident management and investigation policy and processes that align to your organizational requirements. Run incident response simulations and use tools with automation to increase your speed for detection, investigation, and recovery.\nQuestions and best practices The last two components of the framework are questions and best practices. You can use questions to validate whether a specific best practice is in place or not. Each pillar has a set of questions and best practices to address those questions. These are best practices, or answers, that customers have been successful with. The answers are not black and white. The answer for the question may be valid given your context of the workload. You will still need to apply your architectural judgement. For example one of the security pillar questions is: How do you protect your data at rest? The framework shows you the context of the question and some of the best practices to be implemented.\nHow to Run a Well-Architected Framework Review  Lien : https://explore.skillbuilder.aws/learn/course/108/play/82454/module-2-how-to-run-a-well-architected-framework-review  Liens  https://explore.skillbuilder.aws/learn/course/internal/view/elearning/108/aws-well-architected-badge  ","date":"2023-08-06T14:52:59+02:00","image":"https://yilas.github.io/p/certifications-aws-well-architected-framework/WA-Arch-Blog-logo-1024x576_hu2b2fa15ba385ed2c38abef41b66288fc_88259_120x120_fill_box_smart1_3.png","permalink":"https://yilas.github.io/p/certifications-aws-well-architected-framework/","title":"AWS well architected framework"},{"content":"AWS well architected framework Lien vers ce cours (gratuit) : https://explore.skillbuilder.aws/learn/course/internal/view/elearning/108/aws-well-architected-badge\nLire la suite\u0026hellip;\nAWS Certified Cloud Practitioner (CLF-C01/CLF-C02)) Lire la suite\u0026hellip;\n","date":"2023-08-06T14:52:59+02:00","image":"https://yilas.github.io/p/certifications-aws/aws-picture_hud47f6e1750a5809cca1495502a28fd4e_70832_120x120_fill_box_smart1_3.png","permalink":"https://yilas.github.io/p/certifications-aws/","title":"Certifications AWS"},{"content":"Introduction Searching for secrets such as passwords, authentication tokens, API keys, AWS keys, etc. in Git repositories is of crucial importance for several reasons linked to IT security and the protection of sensitive data:\n  Protecting sensitive information: Secrets, such as passwords and API keys, are used to access sensitive resources or specific services. If they are exposed publicly in a Git repository, this can lead to potential security breaches and compromise data confidentiality and integrity.\n  Attack prevention: Hackers actively seek out secrets exposed in Git repositories to gain illegal access to sensitive systems and data. Proactively searching for these secrets helps prevent potential attacks before they happen.\n  Security compliance: Numerous security regulations and standards, such as the RGPD (General Data Protection Regulation), require organizations to take steps to protect sensitive information. Detecting and properly managing secrets exposed in Git repositories is essential to comply with these requirements.\n  Protecting cloud service access keys: Cloud service access keys, such as AWS keys, are used to access an organization\u0026rsquo;s cloud resources and services. Exposing these keys in Git repositories can result in high costs due to unauthorized use of cloud services.\n  Securing open source projects: Many open source projects are hosted on version control platforms such as GitHub. Searching for secrets in these projects is essential to ensure their security and prevent malicious actors from exploiting vulnerabilities.\n  Developer security awareness: By actively searching for secrets in Git repositories, developers are made aware of the risks associated with the accidental inclusion of sensitive information in source code. This encourages them to adopt good secret management practices.\n  Some tools are used to hunt that kind of secrets. Here are 3 tools on which I will focus :\n NoseyParker GitLeaks TruffleHog  NoseyParker NoseyParker is an open source tool designed to search and identify sensitive information and secrets in public code repositories on GitHub. It is primarily a code scanning tool that seeks to detect private information that may be inadvertently exposed in public source code. Although NoseyParker is useful for public repositories, it is not suitable for private repositories or other version control systems.\nGitLeaks GitLeaks is another popular open source tool used to search for secrets and sensitive information in Git repositories. It supports both public and private repositories, making it more versatile than NoseyParker. GitLeaks works by performing a static analysis of Git repositories to detect potentially exposed passwords, API keys, authentication tokens and other sensitive information. Detection rules can also be customized to suit the specific needs of each project.\nTruffleHog TruffleHog is an open source security tool designed specifically to detect sensitive secrets that might be exposed in Git repositories. It performs an in-depth search of the entire repository history, enabling it to find sensitive information even if it has been removed from the current code. TruffleHog is capable of detecting a wide range of sensitive information, including encryption keys, passwords, API keys and other types of secrets. It is particularly useful in collaborative development environments where several people may contribute to the code and accidentally introduce sensitive information.\nInstallation All tools are installed by using asdf (TBD). More installations possibities are given in detail, for each applications.\nNoseyParker The installation can be done with pre-built binaries, docker images or from source.\nResults are stored in a datastore, a SQLite database.\nScan 1  noseyparker scan --datastore ~/tmp/gitlab-dump.db .   An example of output returned by that command\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  Rule Distinct Matches Total Matches ───────────────────────────────────────────────────────────────────────────── Generic Password (single quoted) 142 2,650 Generic Secret 95 1,409 Generic API Key 92 826 JSON Web Token (base64url-encoded) 70 407 PEM-Encoded Private Key 63 141 Generic Password (double quoted) 59 515 Generic Username and Password (unquoted) 31 116 AWS API Key 30 279 bcrypt Hash 24 63 Generic Username and Password (quoted) 22 92 Sauce Token 16 40 netrc Credentials 13 93 AWS Secret Access Key 11 71 AWS Account ID 10 260 Credentials in ODBC Connection String 6 30 OpenAI API Key 4 5 GitLab Personal Access Token 4 55 Slack Webhook 3 31 Google OAuth Client Secret 3 73 Google Client ID 3 4 Shopify Domain 2 3 Google API Key 2 5 Slack 1 1 CodeClimate 1 7   Reporting Multiple output formats are available : human, json, jsonl and sarif (Static Analysis Results Interchange Format).\n1  noseyparker report --datastore ~/tmp/gitlab-dump -f jsonl   The output of the report, in an human format,\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  Match: AKIA111111111EXAMPLE Occurrence 1/2 Git repo: gitlab-dump/repo01/.git Blob: af5626b4a114abcb82d63db7c8082c3c4756e51b Lines: 870:31-870:50 \u0026#34;UserName\u0026#34;: \u0026#34;Alice\u0026#34; }, \u0026#34;output\u0026#34;: { \u0026#34;AccessKeyMetadata\u0026#34;: [ { \u0026#34;AccessKeyId\u0026#34;: \u0026#34;AKIA111111111EXAMPLE\u0026#34;, \u0026#34;CreateDate\u0026#34;: \u0026#34;2018-12-01T22:19:58Z\u0026#34;, \u0026#34;Status\u0026#34;: \u0026#34;Active\u0026#34;, \u0026#34;UserName\u0026#34;: \u0026#34;Alice\u0026#34; Occurrence 2/2 Git repo: gitlab-dump/repo01/.git Blob: af5626b4a114abcb82d63db7c8082c3c4756e51b Lines: 699:31-699:50 \u0026#34;UserName\u0026#34;: \u0026#34;Alice\u0026#34; }, \u0026#34;output\u0026#34;: { \u0026#34;AccessKeyMetadata\u0026#34;: [ { \u0026#34;AccessKeyId\u0026#34;: \u0026#34;AKIA111111111EXAMPLE\u0026#34;, \u0026#34;CreateDate\u0026#34;: \u0026#34;2018-12-01T22:19:58Z\u0026#34;, \u0026#34;Status\u0026#34;: \u0026#34;Active\u0026#34;, \u0026#34;UserName\u0026#34;: \u0026#34;Alice\u0026#34;   Pros / Cons  Pros:  Time to scan. Here is an example    1 2 3  Found 42.37 GiB from 293,195 plain files and 514,137 blobs from 632 Git repos [00:00:04] Scanning content ████████████████████ 100% 42.37 GiB/42.37 GiB [00:01:25] Scanned 34.92 GiB from 694,395 blobs in 85 seconds (419.42 MiB/s); 7,176/7,176 new matches    Cons: TBC  Issues I met TBD\nGitleaks Pros / Cons TBD\nIssues I met TBD\nTruffleHog Pros / Cons TBD\nIssues I met TBD\n","date":"2023-07-25T14:17:58+02:00","image":"https://yilas.github.io/p/git-secrets-hunter/telling-secrets-big-e1379620235254_hu6044ea630640ce0a9bc43f5d07a22b56_45132_120x120_fill_q75_box_smart1.jpg","permalink":"https://yilas.github.io/p/git-secrets-hunter/","title":"Secrets hunter"}]